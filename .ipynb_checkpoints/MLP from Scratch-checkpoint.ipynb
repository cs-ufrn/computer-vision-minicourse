{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook imports, do not care about them!\n",
    "import jdc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introdução\n",
    "\n",
    "Redes Neurais de Múltiplas Camadas (RNM) são modelos computacionais inspirados no sistema nervoso humano, compostas por estruturas matemáticas que simulam os neurônios e suas conexões. Os usos mais comuns desses modelos consistem em tarefas de classificação e regressão, \n",
    "o que favorece a aplicação em diversas áreas de pesquisa, sendo uma delas\n",
    "a de Visão Computacional.\n",
    "\n",
    "O objetivo deste *notebook* é apresentar os fundamentos das RNM *feedforward fully connected*, também conhecidas como Multilayer Perceptron (MLP), dos pontos de vista matemático e algorítmico, gerando uma implementação\n",
    "básica de uma MLP em Python. Ao final, é mostrado como a biblioteca Keras pode ser utilizada para simplificar\n",
    "o trabalho com essas redes neurais.\n",
    "\n",
    "Para compreender as RNM, é importante primeiramente conhecer os seus dois principais componentes: os **neurônios** e a **arquitetura em camadas**.\n",
    "\n",
    "## Neurônios\n",
    "Um neurônio, no contexto das redes neurais, é uma estrutura que aceita como argumento um vetor $\\mathbf{x} = \\langle x_1, x_2, \\ldots, x_n \\rangle \\in \\mathbb{R}^n$\n",
    "de entrada e **responde com um valor real** de saída, comumente chamado de **valor de ativação**. Cada neurônio está relacionado a um valor $b \\in \\mathbb{R}$, chamado **bias**, e a um vetor de pesos $\\mathbf{w} = \\langle w_1, w_2, \\ldots, w_n \\rangle \\in \\mathbb{R}^n$, de forma que cada componente $x_i$ da entrada é associada ao peso $w_i$. Ao receber a entrada,\n",
    "o neurônio responde com o valor $f(\\mathbf{x}\\cdot\\mathbf{w} + b)$, onde $f$ é chamada de \n",
    "**função de ativação** e $\\mathbf{x}\\cdot\\mathbf{w} = \\sum_i x_i \\cdot w_i$, ou seja, \n",
    "o produto interno entre $\\mathbf{x}$ e $\\mathbf{w}$, também chamado de $net$ do neurônio. \n",
    "\n",
    "A contante $b$, o *bias*, existe para permitir um ajuste fino \n",
    "do valor de saída por meio de um deslocamento horizontal da função de ativação.\n",
    "\n",
    "Uma função comum de ativação é a **sigmoide**, expressa pela equação:\n",
    "$$f(x) = \\frac{1}{1 + e^{-x}}.$$\n",
    "\n",
    "Ela possui a importante propriedade de ser contínua e derivável em $(-\\infty, +\\infty)$,\n",
    "o que favorece o algoritmo de treinamento a ser em breve explicado, apesar de existirem algumas desvantagens em sua utilização. O gráfico dessa função, expresso abaixo, evidencia essas propriedades:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdf4142f278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "X = np.arange(-10,10,.1)\n",
    "plt.plot(X,1/(1+np.exp(-X)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arquitetura em camadas\n",
    "\n",
    "Uma RNM é organizada em uma sequência de $k > 2$ camadas de neurônios, denotadas aqui por $L_0, L_1, \\ldots, L_{k-1}$. O tamanho de uma camada $L_i$, denotado aqui por $tam\\;L_i$, é a quantidade de neurônios que ela possui. A camada $L_0$ é dita de entrada, na qual existe um **neurônio de entrada** para cada componente do vetor de entrada da rede. Esses neurônios se diferenciam dos demais porque,\n",
    "ao invés de aceitarem todo o vetor, recebem apenas uma componente e simplesmente a **transmitem** para o interior da rede, sem \n",
    "a aplicação da função de ativação. Já a camada $L_{k-1}$ é dita de saída,\n",
    "e a sua resposta é a resposta da rede. As demais camadas são chamadas de **camadas escondidas**.\n",
    "\n",
    "O que viabiliza o funcionamento do modelo são as conexões entre essas camadas, e elas podem ocorrer de diversas maneiras na rede. Aqui,  \n",
    "o objeto de estudo são as **redes densas *feedforward***, em que cada neurônio da camada $L_i$ se conecta com\n",
    "todos os neurônios da camada $L_{i+1}$, $i = 0,\\ldots, k-2$, de maneira que o vetor de entrada dos neurônios da camada $L_{i+1}$ é o vetor composto pelas\n",
    "respostas dos neurônios da camada $L_{i}$. Assim, um neurônio na camada $L_{i+1}$ recebe, como entrada, um vetor\n",
    "de dimensão $tam\\;L_i$, $i=0,1, \\ldots, k-2$.\n",
    "\n",
    "Cada conexão entre neurônios pode ser vista como associada ao peso que o neurônio\n",
    "atribui ao valor por ela provido. Essa visão possibilita a utilização de uma\n",
    "notação muito útil para se trabalhar com pesos: denota-se por $w_{ij}^l$ o peso \n",
    "da conexão entre o neurônio $j$ da camada $l-1$ com o neurônio $i$ da camada $l$,\n",
    "$l = 1, \\ldots, k-1$. Mais ainda, é possível representar todas as conexões entre\n",
    "duas camadas por uma matriz de pesos $\\mathbf{W}^l = (w_{ij}^l)$ de dimensão $tam\\;L_{l} \\times tam\\;L_{l-1}$.\n",
    "Para facilitar a identificação dos *biases* de cada neurônio em uma camada, denota-se por \n",
    "$\\mathbf{b}^l = \\langle b^l_1, b^l_2, \\ldots, b^l_{tam\\;L_l} \\rangle$ os *biases* \n",
    "dos neurônios da camada $L_l$, sendo $b^l_i$ o *bias* do neurônio $i$ na camada $L_l$.\n",
    "\n",
    "Sabendo disso, já é possível iniciar a implementação em Python da RNM!\n",
    "\n",
    "### A classe `MultilayerNeuralNetwork`\n",
    "\n",
    "Como o objetivo é\n",
    "produzir um módulo reutilizável, os recursos de orientação a objetos da linguagem Python\n",
    "serão aplicados. Além disso, o pacote `numpy` será utilizado para a manipulação de matrizes. \n",
    "\n",
    "A programação tem início com a importação do `numpy` (ele foi importado antes, para o gráfico da sigmoide, mas repetimos aqui por questões didáticas) e a declaração da classe `MultilayerNeuralNetwork`, a qual encapsulará todos os dados e métodos necessários ao\n",
    "funcionamento e à utilização da rede, como a matriz de pesos, a arquitetura e as rotinas de treinamento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "class MultilayerNeuralNetwork:\n",
    "    '''A Multilayer Dense Feedforward Neural Network implementation.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essa é apenas uma classe, e nada tem a ver com redes neurais além do nome simplesmente. O próximo passo é criar um **construtor**, método que sempre será chamado quando alguém\n",
    "criar (ou, mais tecnicamente, instanciar) a rede neural. Nele, é importante garantir\n",
    "a criação e inicialização da arquitetura, o que implica na configuração das camadas (quantas e quantos neurônios devem possuir), das matrizes de pesos e dos vetores de *bias*.  Estas serão inicializadas com valores aleatórios, seguindo\n",
    "a distribuição normal, e, em seguida, normalizadas pela raiz quadrada da quantidade de neurônios da camada correspondente. A inicialização dos pesos é um tópico importante, para o qual existem diversas propostas, mas que será abstraído neste momento por economia de tempo.\n",
    "Além disso, um parâmetro `alpha` será acrescentado, \n",
    "cuja existência será justificada mais adiante. Portanto, o construtor receberá do\n",
    "usuário a **arquitetura da rede**, no formato $[tam\\;L_0, tam\\;L_1, \\ldots, tam\\;L_{k-1}]$, e o tal `alpha`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "    %%add_to MultilayerNeuralNetwork\n",
    "    def __init__(self, arch = [1,2,1], alpha = 0.1):\n",
    "        '''Initialize the network.'''\n",
    "        \n",
    "        # A dictionary to store the weight matrices\n",
    "        self.W = {}\n",
    "        # A dictionary to store the biases vectors\n",
    "        self.B = {}\n",
    "        # The learning rate (to be explained later)\n",
    "        self.alpha = alpha\n",
    "        # The arch answers the questions: how many layers and how many neurons in each layer.\n",
    "        self.arch = arch\n",
    "        \n",
    "        # Initialize the weight matrix and biases with normalized random values\n",
    "        for i in np.arange(1,len(self.arch)):\n",
    "            # Weights\n",
    "            w = np.random.randn(self.arch[i], self.arch[i-1])\n",
    "            self.W[i] = w/np.sqrt(self.arch[i])\n",
    "            # Biases\n",
    "            b = np.random.randn(self.arch[i],1)\n",
    "            self.B[i] = b/np.sqrt(self.arch[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como será utilizada a função sigmoide para a ativação dos neurônios, é importante\n",
    "que ela e sua derivada estejam implementadas na classe:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "    %%add_to MultilayerNeuralNetwork\n",
    "    def sigmoid(self, x):\n",
    "        '''Sigmoid function.'''\n",
    "        return 1.0/(1 + np.exp(-x))\n",
    "    \n",
    "    def sigmoid_deriv(self, x):\n",
    "        '''Derivative of the sigmoid function, considering that x is the result\n",
    "        of applying the sigmoid function to the net.\n",
    "        '''\n",
    "        return x * (1 - x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com isso, é possível instanciar uma rede, mesmo que não se possa fazer nada com ela ainda, apenas para checar a sua estrutura:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: array([[ 0.62241839, -0.4115444 ],\n",
      "       [-0.24544894, -0.48619569],\n",
      "       [-0.63678414, -0.62999147]]), 2: array([[ 0.8857191 ,  0.32543977, -0.21077289]])}\n",
      "{1: array([[-0.91458142],\n",
      "       [ 0.75273368],\n",
      "       [-0.01497279]]), 2: array([[ 0.26350503]])}\n"
     ]
    }
   ],
   "source": [
    "# Creating an architecture with 2 neurons in the input layer, 3 in the unique hidden layer\n",
    "# and 1 in the output layer\n",
    "neuralnet = MultilayerNeuralNetwork(arch = [2,3,1], alpha = 0.5)\n",
    "print(neuralnet.W)\n",
    "print(neuralnet.B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Respostas das camadas\n",
    "\n",
    "Note que cada camada produz um vetor de resposta composto pelas respostas individuais\n",
    "de cada um de seus neurônios. Denote por $\\mathbf{a^l} = \\langle a^l_1, a^l_2, \\ldots, a^l_{tam\\; L_l} \\rangle$ esse vetor para a camada $L_l$. Como visto, ele deverá ser a entrada para a camada seguinte, mas os seus valores serão combinados de forma particular\n",
    "pela matriz de pesos $\\mathbf{W}^{l+1}$. A expressão\n",
    "\n",
    "$$\\mathbf{z}^l = \\mathbf{W}^{l+1}\\cdot\\mathbf{a}^l + \\mathbf{b}^l$$\n",
    "\n",
    "produz um vetor cujos componentes são os valores $net$ de cada neurônio da camada\n",
    "$L_{l+1}$. Sabendo disso, qual seria a expressão para o vetor de saída da camada $L_{l+1}$, ou seja, para $\\mathbf{a}^{l+1}$?\n",
    "Basta aplicar a função de ativação a cada componente do vetor obtido! Considerando-se a aplicação da função ponto a ponto, ou seja, $f(\\langle x_1, x_2, \\ldots, x_n \\rangle) = \\langle f(x_1), f(x_2), \\ldots, f(x_n) \\rangle$, tem-se que:\n",
    "\n",
    "$$\\mathbf{a}^{l+1} = f(\\mathbf{W}^{l+1}\\cdot\\mathbf{a}^l + \\mathbf{b}^l) = f(\\mathbf{z}^l).$$\n",
    "\n",
    "O conhecimento adquirido até este ponto é suficiente para se entender a arquitetura de uma rede neural e como computar as saídas das suas camadas de neurônios a partir \n",
    "de um vetor de entrada. Já podemos implementar uma função muito importante da nossa rede neural: dado um vetor de entrada, qual é o vetor de resposta da rede, ou seja, qual o vetor na camada de saída? Essa função é comumente chamada de `predict`, pois é utilizada para gerar a previsão (resposta) da rede a partir de uma entrada. Note como é simples e advém diretamente da definição:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "    %%add_to MultilayerNeuralNetwork\n",
    "    def predict(self, X, outputs=False):\n",
    "        ''' Given a matrix of input line vectors X, compute the output of the network. '''\n",
    "        # Set the result of the input layer to be column vectors\n",
    "        p = np.atleast_2d(X).T\n",
    "        # Store outputs?\n",
    "        if outputs: \n",
    "            A = {}\n",
    "            A[0] = p\n",
    "        # Compute the output of each layer, following the definition\n",
    "        for layer in np.arange(1, len(self.arch)):\n",
    "            p = self.sigmoid(np.dot(self.W[layer], p) + self.B[layer])\n",
    "            if outputs: A[layer] = p\n",
    "        # Return accordingly to outputs option\n",
    "        return A if outputs else p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ocorre que apenas saber como obter a saída da rede não resolve problema algum: as matrizes de pesos aleatórios \n",
    "tornam o modelo inútil. Ele necessita se ajustar (lê-se \"aprender\")\n",
    "para solucionar os problemas com os quais é confrontado, e é disso que \n",
    "trataremos a partir de agora!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aprendizado em uma RNM\n",
    "\n",
    "O modelo de aprendizagem de redes neurais é geralmente o **supervisionado**, pois faz\n",
    "uso de exemplos representantes da verdade (*ground truth*) para fazer\n",
    "com que a rede gere as respostas desejadas após uma **etapa de treinamento**. É como se um professor\n",
    "apresentasse a entrada, a rede respondesse e ele informasse qual foi o \n",
    "erro cometido. A rede, com base nisso, modifica sua estrutura (suas matrizes\n",
    " de pesos) para que o erro, da próxima vez que o professor mostrar\n",
    " o exemplo, seja garantidamente menor. Esse processo termina quando algum critério de parada é atingido. Os mais comuns são o erro máximo e o número de ciclos ou *epochs*.\n",
    " \n",
    " Um problema a ser resolvido com aprendizado de máquinas geralmente provê um conjunto com $N$ exemplos\n",
    " \n",
    " $$\\mathcal{D} = \\{\\langle \\mathbf{x_1}, \\mathbf{y_1} \\rangle\\, \\langle \\mathbf{x_2}, \\mathbf{y_2} \\rangle\\, \\ldots, \\langle \\mathbf{x_N}, \\mathbf{y_N} \\rangle\\}$$\n",
    " \n",
    " sendo $\\mathbf{x_i} \\in \\mathbb{R}^d$ os vetores de entrada da rede e $\\mathbf{x_i} \\in \\mathbb{R}^e$ a\n",
    " resposta esperada para a rede, também chamada de ***target*** ou **classe**. \n",
    " \n",
    " É prática comum \n",
    " particionar esse conjunto em dois outros: um para o treinamento da rede, denotado por $\\mathcal{T}$,\n",
    " e outro para o teste do modelo treinado, denotado por $\\mathcal{T^*}$. Tamanhos comuns para o conjunto de treino são $65\\%$, $70\\%$ ou $75\\%$ de $|\\mathcal{D}|$. A biblioteca `sklearn`, em Python,\n",
    " provê a função `train_test_split`, que realiza esse particionamento.\n",
    " \n",
    " O erro cometido pela rede, ao responder para dado exemplo $\\langle \\mathbf{x}, \\mathbf{y} \\rangle \\in \\mathcal{D}$, é modelado matematicamente por uma **função de custo**\n",
    " $C_x:\\mathbb{R}^{w+1} \\to \\mathbb{R}$, onde $w$ é a quantidade de pesos (como calcular $w$ a partir da arquitetura?). As funções que podem desempenhar esse papel devem cumprir alguns requisitos\n",
    " básicos e dependem dos valores dos pesos e dos *biases*. Uma das mais comuns é a do **erro quadrático**, de equação:\n",
    " \n",
    " $$C_x = \\frac 1 2 ||\\mathbf{y}- \\mathbf{a}^{k-1}(\\mathbf{x})||^2 = \\frac 1 2 \\sum_i (y_i - a^{k-1}_i(\\mathbf{x}))^2,$$\n",
    "  onde $a^{k-1}(\\mathbf{x})$ é a saída da última camada da rede para o exemplo $\\langle \\mathbf{x}, \\mathbf{y} \\rangle$ (que nossa rede já sabe computar). Note que\n",
    " quanto maior a diferença entre a verdade e a saída da rede, maior o valor dessa\n",
    " função, o que mostra sua adequação para representar o erro.\n",
    " \n",
    " A fim de representar o erro com respeito a todos os exemplos, define-se também a função\n",
    " de custo $\\bar{C}:\\mathbb{R}^{w+1} \\to \\mathbb{R}$, dada pela média dos erros para cada exemplo, ou seja:\n",
    " \n",
    " $$\n",
    "     \\bar{C} = \\frac 1 n \\sum_{\\langle \\mathbf{x}, \\mathbf{y} \\rangle \\in \\mathcal{T}} C_x = \\frac{1}{2n} \\sum_{\\langle \\mathbf{x}, \\mathbf{y} \\rangle \\in \\mathcal{T}} ||\\mathbf{y}- \\mathbf{a}^{k-1}(\\mathbf{x})||^2.\n",
    " $$ \n",
    " \n",
    " Precisaremos, em nossa implementação, do cálculo da função de custo quadrática. Façamos, pois:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "    %%add_to MultilayerNeuralNetwork\n",
    "    def quadratic_loss(self, X, targets):\n",
    "        ''' Compute the total quadratic loss, given a matrix with line vectors. '''\n",
    "        # Transform all line vectors in column vectors\n",
    "        targets = np.atleast_2d(targets).T\n",
    "        # Generate predictions\n",
    "        predictions = self.predict(X)\n",
    "        # Compute loss\n",
    "        loss = (1/X.shape[0])* 0.5 * np.sum((predictions - targets) ** 2)\n",
    "        return loss    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Assim, o objetivo do treinamento é fazer com que o valor de $C_x$ (e $\\bar{C}$, consequentemente), para cada exemplo $\\langle \\mathbf{x}, \\mathbf{y} \\rangle$,\n",
    " seja menor a cada ciclo de treino. Como $C_x$ é função dos pesos e dos *biases*, nada melhor que buscar ajustá-los a fim de alcançar esse objetivo. Esse ajuste ocorre por meio de algum\n",
    " **método de otimização**, cujo objetivo é encontrar um conjunto de valores para pesos e *biases* tal que o valor de $\\bar{C}$ seja tão menor quanto se queira. Um método \n",
    " muito utilizado para tanto chama-se **gradiente descendente**, do qual a próxima seção tratará.\n",
    " \n",
    " ## Gradiente descendente\n",
    " \n",
    " Fujamos do escopo das redes neurais, e tratemos do problema geral de minimizar uma função\n",
    " de múltiplas variáveis $C:\\mathbb{R}^n \\to \\mathbb{R}$. Queremos encontrar o vetor $\\mathbf{v} = \\langle v_1, v_2, \\ldots, v_n \\rangle$ tal que $C(\\mathbf{v}) = C(v_1, v_2, \\ldots, v_n)$ seja um mínimo global de $C$.\n",
    " \n",
    " Para conseguir a intuição sobre o método, vale reduzir a dimensão de entrada de $C$ para\n",
    " duas variáveis, $v_1$ e $v_2$, e imaginar que seu gráfico assume a forma de um vale. Por exemplo:\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7fdf313c10b8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdf412bd8d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mpl_toolkits import mplot3d\n",
    "\n",
    "def quad(x,y):\n",
    "    return x**2 + y**2\n",
    "\n",
    "x = np.linspace(-10,10,30)\n",
    "y = np.linspace(-10,10,30)\n",
    "\n",
    "X,Y = np.meshgrid(x,y)\n",
    "\n",
    "Z = quad(X,Y)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.plot_surface(X,Y,Z,rstride=1, cstride=1, cmap='viridis', edgecolor='none')\n",
    "ax.set_title('Quadratic plot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função acima é bem simples, devemos concordar, e, apenas observando seu gráfico, é possível encontrar o mínimo. Também, utilizando técnicas primárias de cálculo, é possível encontrar o mínimo global sem muito esforço nesse caso. Porém, quando lidamos com aprendizado, geralmente estamos interessados em minimizar funções de dezenas, centenas, milhares de variáveis! É por isso que as técnicas tradicionais de cálculo se tornam inviáveis, e outros métodos entram em cena.\n",
    "\n",
    "O gradiente descendente, sendo um deles, não busca encontrar um mínimo global, mas sim **algum mínimo para a função**. Isso pode ser um problema em alguns casos, mas não se mostra um empecilho grave para o seu uso em muitas aplicações de redes neurais. Imagine uma bola colocada em algum ponto arbitrário do vale mostrado no gráfico acima. Nossa experiência diz que ela começará a rolar até o ponto mais baixo do vale, e esse fato nos dá uma heurística para encontrar um mínimo da função: encontremos uma maneira de mover a bola nas direções\n",
    "$v_1$ e $v_2$ de forma que ela sempre esteja descendo o vale! \n",
    "\n",
    "Já que queremos mover a bola, vamos representar o deslocamento por um vetor $\\Delta v = \\langle \\Delta v_1, \\Delta v_2 \\rangle$. Assumindo a bola inicialmente na posição $v = \\langle v_1, v_2 \\rangle$, qual será a mudança no valor de $C$ causada por esse deslocamento? Ou seja, como podemos estimar o valor de $\\Delta C = C(v+\\Delta v)-C(v)$?\n",
    "Do polinômio de Taylor para o caso Multivariável, temos que\n",
    "\n",
    "$$\\Delta C \\approx \\nabla C(v) \\cdot \\Delta v = \\left \\langle \\frac{\\partial C}{\\partial v_1}, \\frac{\\partial C}{\\partial v_2} \\right \\rangle \\cdot \\langle \\Delta v_1, \\Delta v_2 \\rangle ^T = \\frac{\\partial C}{\\partial v_1}\\Delta v_1 + \\frac{\\partial C}{\\partial v_2} \\Delta v_2.$$\n",
    "\n",
    "Queremos reduzir o valor de $C$, correto? Para isso, devemos escolher um valor de $\\Delta v$ apropriado, tal que $\\Delta C < 0$. Pela equação acima, isso se torna muito fácil! Vamos tomar $\\Delta v$ como\n",
    "\n",
    "$$\\Delta v = -\\alpha \\nabla C^T,$$\n",
    "onde $\\alpha \\in \\mathbb{R}_+$. Ainda não convencido de que o $\\Delta C$ causado por essa variação $\\Delta v$ seja negativa? Vamos substituir:\n",
    "\n",
    "$$\\Delta C \\approx \\nabla C \\cdot \\Delta v = \\nabla C \\cdot (-\\alpha \\nabla C^T) = -\\alpha (\\nabla C \\cdot \\nabla C^T ) = -\\alpha ||\\nabla C||^2 \\leq 0,$$\n",
    "já que $||\\nabla C||^2 \\geq 0$ e $\\alpha > 0$. Isso nos garante que, sempre que escolhermos o $\\Delta v$ daquela forma, o valor do $C$ (o valor do erro!) sempre vai diminuir (claro, dentro dos limites da aproximação).\n",
    "\n",
    "Observe que utilizamos, aqui, uma função de duas variáveis, como forma de simplificação. Porém, note que, nas equações vetoriais acima, esse fato não se mostrou nada relevante! De fato, não importa a dimensão: a regra do gradiente descendente funcionará, e é por isso que podemos utilizá-la em nossa rede neural! Assim, para reduzirmos o valor da função de custo $C$, alteraremos os pesos $\\mathbf w$ e os biases $\\mathbf b$ (as variáveis de $C$) pela regra abaixo, considerando a aplicação em cada variável:\n",
    "\n",
    "$$w_k \\gets w_k + (-\\alpha \\frac{\\partial C}{\\partial w_k})$$\n",
    "$$b_l \\gets b_l + (-\\alpha \\frac{\\partial C}{\\partial b_l})$$\n",
    "\n",
    "No contexto das redes, o parâmetro $\\alpha$ se chama **taxa de aprendizado** (*learning rate*) e, geralmente assumindo um valor pequeno (0.05, por exemplo), almeja diminuir o risco de provocarmos um $\\Delta C$ muito elevado, o que poderia representar uma fuga de um ponto mínimo, ou um muito pequeno, o que atrasaria o processo de otimização.\n",
    "\n",
    "### O gradiente descendente estocástico\n",
    "\n",
    "Suponha que nosso conjunto de treino $\\mathcal{D}$ possua muitas instâncias. Como \n",
    "$C = \\sum_{x \\in \\mathcal{D}} C_x,$\n",
    "computar $\\nabla C$ seria muito custoso, pois envolveria computar todos os valores\n",
    "$\\nabla C_x$ e depois fazer $\\nabla C = \\frac{1}{n} \\sum_{x \\in \\mathcal{D}} \\nabla C_x$.\n",
    "Isso poderia atrasar muito o treinamento! \n",
    "\n",
    "O que comumente se faz é adaptar o método do gradiente descendente para sua versão\n",
    "estocástica. Isso significa particionar aleatoriamente o conjunto $\\mathcal D$ em uma família de conjuntos\n",
    "$\\{\\mathcal{D_i}\\}_i$ de mesma cardinalidade (tamanho) $m$. Seja $\\mathcal{D_j} = \\{x^j_1, x^j_2, \\ldots, x^j_m\\}$ algum desses conjuntos e suponha $m$ suficientemente grande.\n",
    "Consideramos que a média entre os $\\nabla C_{x^j_k}$ se aproxime da média dos $\\nabla C_{x}$, ou seja:\n",
    "\n",
    "$$\\frac{\\sum_{k = 1}^m \\nabla C_{x^j_k}}{m} \\approx \\frac{\\sum_{x \\in \\mathcal{D}} \\nabla C_x}{n} = \\nabla C.$$\n",
    "\n",
    "Fantástico! Agora não precisamos pegar sempre o conjunto inteiro e gigantesco $\\mathcal{D}$ para treinar a rede! Basta pegarmos porções menores (chamadas *mini-batches*), estimar $\\Delta C$ utilizando a aproximação acima, e atualizar os pesos e *biases*! Na prática, tomamos um conjunto com $m$  pontos arbitrários, $\\mathcal{D_j} = \\{x^j_1, x^j_2, \\ldots, x^j_m\\}$, e executamos as atualizações:\n",
    "\n",
    "$$w_k \\gets w_k + (-\\frac{\\alpha}{m} \\sum_{p = 1}^m \\frac{\\partial C_{x^j_p}}{\\partial w_k})$$\n",
    "$$b_l \\gets b_l + (-\\frac{\\alpha}{m} \\sum_{p = 1}^m \\frac{\\partial C_{x^j_p}}{\\partial b_l})$$\n",
    "\n",
    "Caso o treinamento ainda não seja o bastante, tomamos outro conjunto de tamanho $m$,\n",
    "e executamos as atualizações. Isso se repete até que o conjunto $\\mathcal{D}$\n",
    "se exaura, marcando o fim de uma *epoch* do treino. As próximas *epochs* repetirão esse processo.\n",
    "\n",
    "Que tal implementarmos nosso *stochastic gradient descent* em nossa rede neural?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "    %%add_to MultilayerNeuralNetwork\n",
    "    def stochastic_gradient_descent(self, D, batch_size):\n",
    "        ''' Update the weights and bias through stochastic gradient \n",
    "        descent optimization. '''\n",
    "        # Get the amount of data points\n",
    "        train_size = len(D)\n",
    "        # Shuffle the data\n",
    "        random.shuffle(D)\n",
    "        # Obtain mini-batches\n",
    "        mini_batches = [D[k : k + batch_size] \n",
    "            for k in range(0, train_size, batch_size)]\n",
    "        # Update weights and biases\n",
    "        for mini_batch in mini_batches:\n",
    "            self.optimize_mini_batch(mini_batch)\n",
    "    \n",
    "    def optimize_mini_batch(self, mini_batch):\n",
    "        ''' Given a minibatch {<x1,y1>,<x2,y2>,...,<xm,ym>}, optimize the cost function. '''\n",
    "        # Get the mini-batch size\n",
    "        m = len(mini_batch)\n",
    "        # Gradient of C\n",
    "        GCw = {}\n",
    "        GCb = {}\n",
    "        # Initialize with zeroes\n",
    "        for i in np.arange(1,len(self.arch)):\n",
    "            GCw[i] = np.zeros(self.W[i].shape)\n",
    "            GCb[i] = np.zeros(self.B[i].shape)\n",
    "        # Use the SGD update rules for teaching the neural network for each batch point\n",
    "        for x, y in mini_batch:\n",
    "            # Compute gradients: see next section to understand how!\n",
    "            Gw, Gb = self.compute_gradient(x, y)\n",
    "            for i in np.arange(1,len(self.arch)): \n",
    "                GCw[i] += Gw[i]\n",
    "                GCb[i] += Gb[i]\n",
    "        # Apply rules for updating weights and biases\n",
    "        for l in np.arange(1,len(self.arch)):\n",
    "            self.W[l] = self.W[l] - (self.alpha/m)*(GCw[l])\n",
    "            self.B[l] = self.B[l] - (self.alpha/m)*(GCb[l])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta seção nos deu um método muito poderoso para nossa rede neural aprender\n",
    "com a experiência! Existe, porém, um ponto ainda obscuro... **Como calcular o gradiente?** Ou melhor, como calcular de forma eficiente? O algoritmo da próxima seção tratará exatamente disso! Vamos aproveitar a estrutura em camadas da nossa rede para computar rapidamente gradientes de forma brilhante!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    " ## O algoritmo Backpropagation\n",
    " \n",
    " Por questões de simplicidade, consideraremos um exemplo fixo $\\langle \\mathbf{x}, \\mathbf{y} \\rangle$, e chamaremos $C_x$ de $C$.\n",
    " \n",
    "O ajuste dos pesos, pelo método do gradiente descendente, como visto, demanda o conhecimento sobre como variações nas matrizes\n",
    " de pesos - de camadas diferentes da última, inclusive - e dos *biases* afetam o resultado da função de custo. Em outras palavras, queremos conhecer as derivadas\n",
    " \n",
    " $$\\frac{\\partial C}{\\partial w_{ij}^l} \\qquad \\frac{\\partial C}{\\partial b_{i}^l},$$\n",
    " para todos os $w_{ij}^l$ e $b_{i}^l$, o que nos permitirá utilizar as regras de atualização do gradiente descendente e fazer a rede neural aprender.\n",
    " \n",
    " Computá-los de forma explícita seria dispendioso. Existe, porém, um caminho implícito. Imagine que o neurônio $j$ da camada $L_l$\n",
    " deva produzir o valor $net$ denotado por $z_j^l$. Porém, suponha que esse valor\n",
    " seja alterado por uma quantidade pequena $\\Delta z_j^l$, de tal forma que a resposta dele\n",
    " seja $f(z_j^l + \\Delta z_j^l)$. Como a função de custo é afetada por essa mudança?\n",
    " Do polinômio de Taylor para o Cálculo Multivariável, chega-se que \n",
    " \n",
    " $$\\Delta C = \\frac{\\partial C}{\\partial z_{j}^l} \\Delta z_{j}^l.$$\n",
    " \n",
    " Note que, se $\\frac{\\partial C}{\\partial z_{j}^l}$ \n",
    " possuir um valor alto, é necessário um $\\Delta z_{j}^l$ de sinal oposto\n",
    " para reduzir o custo. Se possuir um valor próximo de zero, \n",
    " como $\\Delta z_j^l$ é pequeno, não se pode fazer muito para reduzir o custo, e o neurônio é dito estar\n",
    " em estado próximo do ótimo. Assim, faz sentido definir o erro nesse neurônio, \n",
    " denotado por $\\delta_j^l$, como\n",
    " \n",
    " \\begin{equation}\n",
    " \\delta_j^l = \\frac{\\partial C}{\\partial z_{j}^l}.\n",
    " \\end{equation}\n",
    " \n",
    " Além disso, define-se o vetor de erros dos neurônios da camada $L_l$ por\n",
    " $\\delta^l = \\langle \\delta^l_1, \\delta^l_2, \\ldots, \\delta^l_{tam\\;L_l} \\rangle$. O algoritmo Backpropagation está fundamentado em quatro equações, das quais se pode obter\n",
    " o gradiente da função de custo, de interesse para as regras de atualização do gradiente descendente. Pode-se dizer que este é o grande viabilizador das redes neurais modernas, incluindo\n",
    "as utilizadas para *Deep Learning*. Para simplificar a notação, considere a camada $L_{k-1}$ (de saída) denotada pelo índice $L$.\n",
    "\n",
    "Resta-nos compreender cada equação.\n",
    "\n",
    "### Uma equação para o $\\delta^L$\n",
    "\n",
    "Esta equação fornece meios para se calcular o erro na camada de saída. A função de custo pode ser vista da forma \n",
    "\n",
    "$$C=C(X_1, X_2, \\ldots, X_{tam\\,L}),$$\n",
    "\n",
    "tal que $X_1 = a_1^L(z^L_1, z^L_2 \\ldots, z^L_{tam\\,L}), X_2 = a_2^L(z^L_1, z^L_2 \\ldots, z^L_{tam\\,L}), \\ldots, X_{tam\\,L} = a_{tam\\, L}^L(z^L_1, z^L_2 \\ldots, z^L_{tam\\,L})$. Pela definição anterior, sabemos que:\n",
    "\n",
    "$$\\delta_j^L = \\frac{\\partial C}{\\partial z_{j}^L}.$$\n",
    "\n",
    "Utilizando a **regra da cadeia** do Cálculo Multivariável, tem-se que\n",
    "\n",
    "$$\\frac{\\partial C}{\\partial z_{j}^L} = \\sum_k \\frac{\\partial C}{\\partial a^L_j}\\frac{\\partial a^L_k}{\\partial z^L_j}.$$\n",
    "\n",
    "Como apenas $a^L_j$ depende de $z^L_j$, todas as $\\frac{\\partial a^L_k}{\\partial z^L_j}$, com $k \\neq j$, serão anuladas, restando que:\n",
    "\n",
    "$$\\frac{\\partial C}{\\partial z_{j}^L} =\\frac{\\partial C}{\\partial a^L_j}\\frac{\\partial a^L_j}{\\partial z^L_j}.$$\n",
    "\n",
    "Como $a^L_j = f(z^L_j)$, \n",
    "\n",
    "$$\\frac{\\partial a^L_j}{\\partial z^L_j} = f'(z^L_j).$$\n",
    "\n",
    "Finalmente, chega-se à equação\n",
    "\n",
    "$$\\delta^L_j = \\frac{\\partial C}{\\partial a^L_j}f'(z_j^L).$$\n",
    "\n",
    "Na forma vetorial, temos:\n",
    "\n",
    "$$\\delta^L = \\nabla C_a \\odot f'(\\mathbf{z}^L),$$\n",
    "onde $\\odot$ é o **produto de Hadamard**, o qual tem o seguinte efeito, para dois vetores:\n",
    "\n",
    "$$\\langle a_1, a_2, \\ldots, a_n \\rangle^T \\odot \\langle b_1, b_2, \\ldots, b_n \\rangle^T = \\langle a_1b_1, a_2b_2,\\ldots,a_nb_n \\rangle^T.$$\n",
    "\n",
    "### Uma equação para o $\\delta^l$ em função de $\\delta^{l+1}$\n",
    "\n",
    "Na equação passada, conseguimos uma forma de calcular os erros da última camada, entretanto, queremos também um modo\n",
    "de se calcularem os erros nas demais camadas. A estratégia é tentar escrever $\\delta^{l}_j = \\frac{\\partial C}{\\partial z^l_j}$ em termos de $\\delta^{l+1}_{j} = \\frac{\\partial C}{\\partial z^{l+1}_j}$. Como? Primeiro, é válido notar que $z_j^{l+1}$, por definição,\n",
    "depende $z_j^l$:\n",
    "\n",
    "$$z_j^{l+1} = \\mathbf{W}^{l+1}_ja^l = \\mathbf{W}^{l+1}_jf(z^l) = \\sum_i w^{l+1}_{ij}f(z^l_i).$$\n",
    "\n",
    "Além disso, $C$ depende de $z_j^{l+1}$, devido à definição recursiva de $a^n$. Com isso, basta aplicar a regra da cadeia novamente, e temos que:\n",
    "\n",
    "$$\\delta_j^l = \\sum_k \\frac{\\partial C}{\\partial z^{l+1}_k}\\frac{\\partial z^{l+1}_k}{\\partial z^l_j} = \\sum_k \\frac{\\partial z^{l+1}_k}{\\partial z^l_k}\\delta^{l+1}_k.$$\n",
    "\n",
    "Diferenciando a expressão para $z_j^{l+1}$, temos que:\n",
    "$$\\frac{\\partial z_k^{l+1}}{\\partial z_j^l} = w^{l+1}_{jk}f'(z^l_j).$$\n",
    "\n",
    "Assim, substituindo, chegamos a:\n",
    "$$\\delta_j^l = \\sum_k w^{l+1}_{jk}\\delta^{l+1}_kf'(z^l_j).$$\n",
    "\n",
    "Podemos obter a versão vetorial da seguinte forma:\n",
    "\n",
    "\\begin{align}\n",
    "\\delta_j^l = & (\\sum_k w^{l+1}_{kj}\\delta^{l+1}_k)f'(z^l_j) \\\\\n",
    "           = & ((w^{l+1}_{j})^T \\cdot \\delta^{l+1})f'(z^l_j)\n",
    "\\end{align}\n",
    "\n",
    "Essa é a forma componente a componente; para obtermos o vetor $\\delta_j$, basta\n",
    "utilizarmos o produto de Hadamard:\n",
    "\n",
    "$$\\delta^l = ((w^{l+1})^T \\cdot \\delta^{l+1}) \\odot f'(z^l)$$\n",
    "\n",
    "### Uma equação para $\\frac{\\partial C}{\\partial b^l_{j}}$\n",
    "\n",
    "Chegou a hora de obtermos as nossas derivadas de interesse! Começaremos por aquelas\n",
    "com respeito aos *biases*. Da regra da cadeira para o cálculo de muitas variáveis, temos que:\n",
    "\n",
    "$$\\frac{\\partial C}{\\partial b^l_{j}}=\\sum_m \\frac{\\partial C}{\\partial z_m^l} \\frac{\\partial z_m^l}{\\partial b_{j}^l}$$\n",
    "\n",
    "Note agora que $\\frac{\\partial z_m^l}{\\partial b_{j}^l}$, quando $m \\neq j$,\n",
    "é zero, pois $z_m^l$ não depende de $b_{j}^l$ nessas condições. Assim, a equação acima\n",
    "se reduz a:\n",
    "\n",
    "$$\\frac{\\partial C}{\\partial b^l_{j}}=\\frac{\\partial C}{\\partial z_j^l} \\frac{\\partial z_j^l}{\\partial b_{j}^l}$$\n",
    "\n",
    "Vamos lembrar a forma de $z_j^l$:\n",
    "\n",
    "$$z_j^l = \\sum_k a^{l-1}_k w^l_{kj} + b^l_j$$\n",
    "\n",
    "Daí, derivando $z_j^l$ com respeito a $b^l_j$, temos:\n",
    "\n",
    "$$\\frac{\\partial z_j^l}{\\partial b_{j}^l} = 1.$$\n",
    "\n",
    "Substituindo na equação mais acima, chegamos que, simplesmente:\n",
    "\n",
    "$$\\frac{\\partial C}{\\partial b^l_{j}}=\\frac{\\partial C}{\\partial z_j^l} = \\delta^l_j.$$\n",
    "\n",
    "### Uma equação para $\\frac{\\partial C}{\\partial w^l_{jk}}$\n",
    "\n",
    "Sabemos que $C$ está em função de $z^l$ e que $z^l$ está em função dos pesos,\n",
    "o que inclui $w_{jk}^l$. Por essa razão, podemos novamente aplicar a regra\n",
    "da cadeia, da seguinte forma:\n",
    "$$\\frac{\\partial C}{\\partial w^l_{jk}}=\\sum_m \\frac{\\partial C}{\\partial z_m^l} \\frac{\\partial z_m^l}{\\partial w_{jk}^l}$$\n",
    "\n",
    "Note que $w^l_{jk}$ apenas influencia no cálculo de $z^l_j$, logo\n",
    "$$\\frac{\\partial C}{\\partial w^l_{jk}}=\\frac{\\partial C}{\\partial z_j^l} \\frac{\\partial z_j^l}{\\partial w_{jk}^l}=\\delta^l_j\\frac{\\partial z_j^l}{\\partial w_{jk}^l}.$$\n",
    "\n",
    "Lembremo-nos de que:\n",
    "$$z_j^{l} = \\mathbf{W^{l}}_j \\cdot \\mathbf{a}^{l-1} = \\sum_i w^{l}_{ji}a^{l-1}_i,$$\n",
    "onde $\\mathbf{W^{l}}_j$ é a $j$-ésima linha de $\\mathbf{W}^l$.\n",
    "\n",
    "Com isso, diferenciando, temos:\n",
    "$$\\frac{\\partial z_j^{l}}{\\partial w_{jk}^l} =  a^{l-1}_k.$$\n",
    "\n",
    "Finalmente, substituindo:\n",
    "$$\\frac{\\partial C}{\\partial w^l_{jk}}= \\delta^l_j a^{l-1}_k.$$\n",
    "\n",
    "\n",
    "Temos, assim, todas as equações fundamentais que constituem o algoritmo\n",
    "Backpropagation, e elas nos dão todas as derivadas parciais de que precisamos para treinar nossa rede com o gradiente descendente! Note que o algoritmo Backpropagation é um método geral de computar derivadas parciais em grafos como os utilizados para representar MLPs, e, portanto, pode ser utilizado em outros métodos de otimização!\n",
    "\n",
    "Agora, resta implementarmos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "    %%add_to MultilayerNeuralNetwork\n",
    "    def compute_gradient(self, x, y):\n",
    "        ''' Use backpropagation equations to compute the gradient of the cost function. '''\n",
    "        # The index of the output layer, L\n",
    "        L = len(self.arch)-1\n",
    "        # Dicts for gradients\n",
    "        Gw = {}\n",
    "        Gb = {}\n",
    "        # Compute the network output for x input sample\n",
    "        A = self.predict(x, outputs=True)\n",
    "        # Declare what will be set of delta vectors \n",
    "        D = {}\n",
    "        # Compute the error for the last neurons, using Equation 1\n",
    "        y = np.atleast_2d(y).T\n",
    "        deltaL = (A[L] - y) * self.sigmoid_deriv(A[L])\n",
    "        # Include in the D matrix\n",
    "        D[L] = deltaL\n",
    "        # Compute each delta{l} = g(delta{l+1}), using Equation 2\n",
    "        for l in np.arange(L-1, 0, -1):\n",
    "            D[l] = (self.W[l+1].T.dot(D[l+1])) * self.sigmoid_deriv(A[l])\n",
    "        for l in np.arange(L, 0, -1):\n",
    "            # Compute derivatives with respect to biases, using Equation 3\n",
    "            Gb[l] = D[l]\n",
    "            # Compute derivatives with respect to biases, using Equation 4\n",
    "            Gw[l] = D[l].dot(A[l-1].T)\n",
    "        # Return all derivatives\n",
    "        return (Gw, Gb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nós temos agora todos os componentes para construir uma função de treino, que chamaremos de `fit`. Ela, basicamente, executará todos os métodos criados acima, informando ao usuário dados importantes sobre o processo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "    %%add_to MultilayerNeuralNetwork\n",
    "    def fit(self, X, Y, batch_size = 20, epochs = 1000, max_loss = 0.001, displayUpdate = 100):\n",
    "        ''' Train the neural network '''\n",
    "        # Assemble T dataset\n",
    "        D = list(zip(X,Y))\n",
    "        # Store losses for returning\n",
    "        losses = [self.quadratic_loss(X,Y)]\n",
    "        # Loop over epochs\n",
    "        current_epoch = 0\n",
    "        while current_epoch < epochs and losses[current_epoch] > max_loss:\n",
    "            # Optimize using gradient descent\n",
    "            self.stochastic_gradient_descent(D, batch_size)\n",
    "            # Compute and store loss\n",
    "            losses.append(self.quadratic_loss(X,Y))\n",
    "            # Print information\n",
    "            if current_epoch % displayUpdate == 0:\n",
    "                print(\"Epoch: {}, Loss: {:.7f}\".format(current_epoch + 1, losses[current_epoch]))\n",
    "            current_epoch += 1\n",
    "        # Print about stop reason\n",
    "        if losses[current_epoch] < max_loss:\n",
    "            print(\"Stopped by max loss criterion, loss: {:.7f}.\", losses[current_epoch])\n",
    "        elif current_epoch == epochs:\n",
    "            print(\"Stopped by epochs criterion.\")\n",
    "        # Return training information\n",
    "        return (losses, current_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilizando a rede neural\n",
    "\n",
    "Agora que temos nossa rede neural implementada, podemos resolver alguns problemas bastante interessantes. Aqui serão mostrados dois exemplos: o XOR e o reconhecimento de caracteres utilizando o *dataset* MNIST.\n",
    "\n",
    "## XOR\n",
    "\n",
    "XOR é uma operação bem conhecida da lógica proposicional que possui a seguinte tabela verdade:\n",
    "\n",
    "|$x_1$|$x_2$|$y$\n",
    "|---|---|---|\n",
    "|0|0|0|\n",
    "|1|0|1|\n",
    "|0|1|1|\n",
    "|1|1|0|\n",
    "\n",
    "A partir disso, tem-se o *dataset* XOR, composto pelos vetores:\n",
    "$\\langle 0,0 \\rangle, \\langle 1,0 \\rangle, \\langle 0,1 \\rangle, \\langle 1,1 \\rangle$,\n",
    "com os respectivos *labels* $0, 1 , 1, 0$, correspondendo a cada linha da tabela acima. O que acontece se plotarmos \n",
    "$x_1$ no eixo $x$, $x_2$ no eixo $y$ e atribuirmos uma cor para cada um dos dois valores possíveis para $y$? Note:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdf5c1aaa20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x1 = np.array([[0],[1],[0],[1]])\n",
    "x2 = np.array([[0],[0],[1],[1]])\n",
    "\n",
    "plt.scatter(x1,x2,c=['green','red','red','green'])\n",
    "plt.title('The XOR dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O que há de importante nesse *dataset*? **Não é possível separá-lo utilizando uma reta**! Ou seja, não corresponde a um problema de classificação com classes linearmente separáveis. Um neurônio somente não conseguiria resolvê-lo, mas nossa rede pode! Vamos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 0.1493155\n",
      "Epoch: 101, Loss: 0.1227660\n",
      "Epoch: 201, Loss: 0.1167789\n",
      "Epoch: 301, Loss: 0.1060177\n",
      "Epoch: 401, Loss: 0.0972911\n",
      "Epoch: 501, Loss: 0.0918938\n",
      "Epoch: 601, Loss: 0.0820632\n",
      "Epoch: 701, Loss: 0.0444244\n",
      "Epoch: 801, Loss: 0.0176665\n",
      "Epoch: 901, Loss: 0.0094842\n",
      "Epoch: 1001, Loss: 0.0062159\n",
      "Epoch: 1101, Loss: 0.0045424\n",
      "Epoch: 1201, Loss: 0.0035457\n",
      "Epoch: 1301, Loss: 0.0028913\n",
      "Epoch: 1401, Loss: 0.0024318\n",
      "Epoch: 1501, Loss: 0.0020928\n",
      "Epoch: 1601, Loss: 0.0018333\n",
      "Epoch: 1701, Loss: 0.0016288\n",
      "Epoch: 1801, Loss: 0.0014636\n",
      "Epoch: 1901, Loss: 0.0013277\n",
      "Epoch: 2001, Loss: 0.0012140\n",
      "Epoch: 2101, Loss: 0.0011176\n",
      "Epoch: 2201, Loss: 0.0010349\n",
      "Epoch: 2301, Loss: 0.0009631\n",
      "Epoch: 2401, Loss: 0.0009004\n",
      "Epoch: 2501, Loss: 0.0008450\n",
      "Epoch: 2601, Loss: 0.0007959\n",
      "Epoch: 2701, Loss: 0.0007520\n",
      "Epoch: 2801, Loss: 0.0007125\n",
      "Epoch: 2901, Loss: 0.0006769\n",
      "Epoch: 3001, Loss: 0.0006445\n",
      "Epoch: 3101, Loss: 0.0006150\n",
      "Epoch: 3201, Loss: 0.0005880\n",
      "Epoch: 3301, Loss: 0.0005632\n",
      "Epoch: 3401, Loss: 0.0005404\n",
      "Epoch: 3501, Loss: 0.0005193\n",
      "Epoch: 3601, Loss: 0.0004997\n",
      "Epoch: 3701, Loss: 0.0004815\n",
      "Epoch: 3801, Loss: 0.0004646\n",
      "Epoch: 3901, Loss: 0.0004487\n",
      "Epoch: 4001, Loss: 0.0004339\n",
      "Epoch: 4101, Loss: 0.0004200\n",
      "Epoch: 4201, Loss: 0.0004070\n",
      "Epoch: 4301, Loss: 0.0003947\n",
      "Epoch: 4401, Loss: 0.0003831\n",
      "Epoch: 4501, Loss: 0.0003722\n",
      "Epoch: 4601, Loss: 0.0003618\n",
      "Epoch: 4701, Loss: 0.0003520\n",
      "Epoch: 4801, Loss: 0.0003428\n",
      "Epoch: 4901, Loss: 0.0003339\n",
      "Epoch: 5001, Loss: 0.0003255\n",
      "Epoch: 5101, Loss: 0.0003175\n",
      "Epoch: 5201, Loss: 0.0003099\n",
      "Epoch: 5301, Loss: 0.0003026\n",
      "Epoch: 5401, Loss: 0.0002957\n",
      "Epoch: 5501, Loss: 0.0002891\n",
      "Epoch: 5601, Loss: 0.0002827\n",
      "Epoch: 5701, Loss: 0.0002766\n",
      "Epoch: 5801, Loss: 0.0002708\n",
      "Epoch: 5901, Loss: 0.0002652\n",
      "Epoch: 6001, Loss: 0.0002598\n",
      "Epoch: 6101, Loss: 0.0002546\n",
      "Epoch: 6201, Loss: 0.0002496\n",
      "Epoch: 6301, Loss: 0.0002449\n",
      "Epoch: 6401, Loss: 0.0002403\n",
      "Epoch: 6501, Loss: 0.0002358\n",
      "Epoch: 6601, Loss: 0.0002315\n",
      "Epoch: 6701, Loss: 0.0002274\n",
      "Epoch: 6801, Loss: 0.0002234\n",
      "Epoch: 6901, Loss: 0.0002195\n",
      "Epoch: 7001, Loss: 0.0002158\n",
      "Epoch: 7101, Loss: 0.0002122\n",
      "Epoch: 7201, Loss: 0.0002087\n",
      "Epoch: 7301, Loss: 0.0002053\n",
      "Epoch: 7401, Loss: 0.0002020\n",
      "Epoch: 7501, Loss: 0.0001989\n",
      "Epoch: 7601, Loss: 0.0001958\n",
      "Epoch: 7701, Loss: 0.0001928\n",
      "Epoch: 7801, Loss: 0.0001899\n",
      "Epoch: 7901, Loss: 0.0001871\n",
      "Epoch: 8001, Loss: 0.0001844\n",
      "Epoch: 8101, Loss: 0.0001817\n",
      "Epoch: 8201, Loss: 0.0001791\n",
      "Epoch: 8301, Loss: 0.0001766\n",
      "Epoch: 8401, Loss: 0.0001742\n",
      "Epoch: 8501, Loss: 0.0001718\n",
      "Epoch: 8601, Loss: 0.0001695\n",
      "Epoch: 8701, Loss: 0.0001672\n",
      "Epoch: 8801, Loss: 0.0001650\n",
      "Epoch: 8901, Loss: 0.0001629\n",
      "Epoch: 9001, Loss: 0.0001608\n",
      "Epoch: 9101, Loss: 0.0001588\n",
      "Epoch: 9201, Loss: 0.0001568\n",
      "Epoch: 9301, Loss: 0.0001548\n",
      "Epoch: 9401, Loss: 0.0001530\n",
      "Epoch: 9501, Loss: 0.0001511\n",
      "Epoch: 9601, Loss: 0.0001493\n",
      "Epoch: 9701, Loss: 0.0001475\n",
      "Epoch: 9801, Loss: 0.0001458\n",
      "Epoch: 9901, Loss: 0.0001441\n",
      "Epoch: 10001, Loss: 0.0001425\n",
      "Epoch: 10101, Loss: 0.0001409\n",
      "Epoch: 10201, Loss: 0.0001393\n",
      "Epoch: 10301, Loss: 0.0001378\n",
      "Epoch: 10401, Loss: 0.0001363\n",
      "Epoch: 10501, Loss: 0.0001348\n",
      "Epoch: 10601, Loss: 0.0001334\n",
      "Epoch: 10701, Loss: 0.0001319\n",
      "Epoch: 10801, Loss: 0.0001306\n",
      "Epoch: 10901, Loss: 0.0001292\n",
      "Epoch: 11001, Loss: 0.0001279\n",
      "Epoch: 11101, Loss: 0.0001266\n",
      "Epoch: 11201, Loss: 0.0001253\n",
      "Epoch: 11301, Loss: 0.0001241\n",
      "Epoch: 11401, Loss: 0.0001228\n",
      "Epoch: 11501, Loss: 0.0001216\n",
      "Epoch: 11601, Loss: 0.0001204\n",
      "Epoch: 11701, Loss: 0.0001193\n",
      "Epoch: 11801, Loss: 0.0001182\n",
      "Epoch: 11901, Loss: 0.0001170\n",
      "Epoch: 12001, Loss: 0.0001159\n",
      "Epoch: 12101, Loss: 0.0001149\n",
      "Epoch: 12201, Loss: 0.0001138\n",
      "Epoch: 12301, Loss: 0.0001128\n",
      "Epoch: 12401, Loss: 0.0001118\n",
      "Epoch: 12501, Loss: 0.0001108\n",
      "Epoch: 12601, Loss: 0.0001098\n",
      "Epoch: 12701, Loss: 0.0001088\n",
      "Epoch: 12801, Loss: 0.0001079\n",
      "Epoch: 12901, Loss: 0.0001069\n",
      "Epoch: 13001, Loss: 0.0001060\n",
      "Epoch: 13101, Loss: 0.0001051\n",
      "Epoch: 13201, Loss: 0.0001042\n",
      "Epoch: 13301, Loss: 0.0001034\n",
      "Epoch: 13401, Loss: 0.0001025\n",
      "Epoch: 13501, Loss: 0.0001017\n",
      "Epoch: 13601, Loss: 0.0001008\n",
      "Epoch: 13701, Loss: 0.0001000\n",
      "Epoch: 13801, Loss: 0.0000992\n",
      "Epoch: 13901, Loss: 0.0000984\n",
      "Epoch: 14001, Loss: 0.0000976\n",
      "Epoch: 14101, Loss: 0.0000969\n",
      "Epoch: 14201, Loss: 0.0000961\n",
      "Epoch: 14301, Loss: 0.0000954\n",
      "Epoch: 14401, Loss: 0.0000946\n",
      "Epoch: 14501, Loss: 0.0000939\n",
      "Epoch: 14601, Loss: 0.0000932\n",
      "Epoch: 14701, Loss: 0.0000925\n",
      "Epoch: 14801, Loss: 0.0000918\n",
      "Epoch: 14901, Loss: 0.0000911\n",
      "Epoch: 15001, Loss: 0.0000905\n",
      "Epoch: 15101, Loss: 0.0000898\n",
      "Epoch: 15201, Loss: 0.0000892\n",
      "Epoch: 15301, Loss: 0.0000885\n",
      "Epoch: 15401, Loss: 0.0000879\n",
      "Epoch: 15501, Loss: 0.0000873\n",
      "Epoch: 15601, Loss: 0.0000867\n",
      "Epoch: 15701, Loss: 0.0000860\n",
      "Epoch: 15801, Loss: 0.0000854\n",
      "Epoch: 15901, Loss: 0.0000849\n",
      "Epoch: 16001, Loss: 0.0000843\n",
      "Epoch: 16101, Loss: 0.0000837\n",
      "Epoch: 16201, Loss: 0.0000831\n",
      "Epoch: 16301, Loss: 0.0000826\n",
      "Epoch: 16401, Loss: 0.0000820\n",
      "Epoch: 16501, Loss: 0.0000815\n",
      "Epoch: 16601, Loss: 0.0000809\n",
      "Epoch: 16701, Loss: 0.0000804\n",
      "Epoch: 16801, Loss: 0.0000799\n",
      "Epoch: 16901, Loss: 0.0000794\n",
      "Epoch: 17001, Loss: 0.0000789\n",
      "Epoch: 17101, Loss: 0.0000784\n",
      "Epoch: 17201, Loss: 0.0000779\n",
      "Epoch: 17301, Loss: 0.0000774\n",
      "Epoch: 17401, Loss: 0.0000769\n",
      "Epoch: 17501, Loss: 0.0000764\n",
      "Epoch: 17601, Loss: 0.0000759\n",
      "Epoch: 17701, Loss: 0.0000755\n",
      "Epoch: 17801, Loss: 0.0000750\n",
      "Epoch: 17901, Loss: 0.0000745\n",
      "Epoch: 18001, Loss: 0.0000741\n",
      "Epoch: 18101, Loss: 0.0000736\n",
      "Epoch: 18201, Loss: 0.0000732\n",
      "Epoch: 18301, Loss: 0.0000728\n",
      "Epoch: 18401, Loss: 0.0000723\n",
      "Epoch: 18501, Loss: 0.0000719\n",
      "Epoch: 18601, Loss: 0.0000715\n",
      "Epoch: 18701, Loss: 0.0000711\n",
      "Epoch: 18801, Loss: 0.0000707\n",
      "Epoch: 18901, Loss: 0.0000703\n",
      "Epoch: 19001, Loss: 0.0000699\n",
      "Epoch: 19101, Loss: 0.0000695\n",
      "Epoch: 19201, Loss: 0.0000691\n",
      "Epoch: 19301, Loss: 0.0000687\n",
      "Epoch: 19401, Loss: 0.0000683\n",
      "Epoch: 19501, Loss: 0.0000679\n",
      "Epoch: 19601, Loss: 0.0000675\n",
      "Epoch: 19701, Loss: 0.0000672\n",
      "Epoch: 19801, Loss: 0.0000668\n",
      "Epoch: 19901, Loss: 0.0000664\n",
      "Stopped by epochs criterion.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.14931551936270523,\n",
       "  0.1449234313167998,\n",
       "  0.14133331131386989,\n",
       "  0.13793112802367405,\n",
       "  0.13513737004417212,\n",
       "  0.13310885364037472,\n",
       "  0.13127593978468494,\n",
       "  0.12983357612721663,\n",
       "  0.12881157363809831,\n",
       "  0.12804363723434214,\n",
       "  0.1274340554535793,\n",
       "  0.12696914351470462,\n",
       "  0.12672682611193842,\n",
       "  0.12640453276705421,\n",
       "  0.12615734469548393,\n",
       "  0.12596676055077283,\n",
       "  0.12580987723229395,\n",
       "  0.1256854989242398,\n",
       "  0.12558259839837488,\n",
       "  0.12549840673268411,\n",
       "  0.12540903171473139,\n",
       "  0.12533898504688903,\n",
       "  0.12530101799580504,\n",
       "  0.12525490523269195,\n",
       "  0.12522106675979155,\n",
       "  0.12516860871561442,\n",
       "  0.12512326880312061,\n",
       "  0.12508807452918327,\n",
       "  0.12505477985672486,\n",
       "  0.12502266086762731,\n",
       "  0.12499113109435185,\n",
       "  0.12496239218625732,\n",
       "  0.12492149078105119,\n",
       "  0.12488770949008136,\n",
       "  0.12485608927738473,\n",
       "  0.12482532882321154,\n",
       "  0.12480500812329845,\n",
       "  0.12478514394249135,\n",
       "  0.12474788107317594,\n",
       "  0.1247065094615829,\n",
       "  0.12468519415743633,\n",
       "  0.12466667203272214,\n",
       "  0.12462867421302944,\n",
       "  0.12458504348835885,\n",
       "  0.12454681047600702,\n",
       "  0.12451021237395331,\n",
       "  0.12447752281779427,\n",
       "  0.12445225950933619,\n",
       "  0.12442095917944584,\n",
       "  0.12439400438756666,\n",
       "  0.12437234281162349,\n",
       "  0.12433934784412473,\n",
       "  0.12429795586081571,\n",
       "  0.12427332284507137,\n",
       "  0.12424585487209647,\n",
       "  0.12420626932219073,\n",
       "  0.1241795062073513,\n",
       "  0.12415711350154449,\n",
       "  0.12412114801098299,\n",
       "  0.1240887202453423,\n",
       "  0.12405655837027363,\n",
       "  0.12403155427155793,\n",
       "  0.12399699403103842,\n",
       "  0.12396807793780037,\n",
       "  0.12393788267580802,\n",
       "  0.12391150044017807,\n",
       "  0.12387795957602832,\n",
       "  0.12384955758051178,\n",
       "  0.12381927473988759,\n",
       "  0.12378918194563179,\n",
       "  0.12375954813968842,\n",
       "  0.12372891480832816,\n",
       "  0.12369559105984827,\n",
       "  0.12366719406395199,\n",
       "  0.12363308698053221,\n",
       "  0.12361409804228178,\n",
       "  0.12358708579239376,\n",
       "  0.12355179558471321,\n",
       "  0.12351330509958444,\n",
       "  0.12348557542916749,\n",
       "  0.1234581293141281,\n",
       "  0.12342962346920872,\n",
       "  0.12339533291626054,\n",
       "  0.12336337846450898,\n",
       "  0.12332836344227485,\n",
       "  0.12328941605851856,\n",
       "  0.12325566781571697,\n",
       "  0.12322397937406895,\n",
       "  0.12319501167529302,\n",
       "  0.12315526537213703,\n",
       "  0.12312359363696304,\n",
       "  0.12309288594581431,\n",
       "  0.12305522190366477,\n",
       "  0.12301746152129842,\n",
       "  0.12298098193446287,\n",
       "  0.12294729322702121,\n",
       "  0.12291011574406469,\n",
       "  0.12288133417824962,\n",
       "  0.12284322613741032,\n",
       "  0.12280048544992492,\n",
       "  0.12276600296771627,\n",
       "  0.12273204502573554,\n",
       "  0.12269318767130702,\n",
       "  0.12265311863858094,\n",
       "  0.12261608115998908,\n",
       "  0.12258120687548571,\n",
       "  0.12254689497954779,\n",
       "  0.12250072486183276,\n",
       "  0.12246532595522736,\n",
       "  0.12243383512268594,\n",
       "  0.12238769883395606,\n",
       "  0.12234594746677377,\n",
       "  0.1223065246827274,\n",
       "  0.12226817382267971,\n",
       "  0.12222861468920726,\n",
       "  0.12219289284462082,\n",
       "  0.12214657219675998,\n",
       "  0.12210346271812511,\n",
       "  0.12206180421670074,\n",
       "  0.12202068142211359,\n",
       "  0.12197861201680382,\n",
       "  0.12193280037967749,\n",
       "  0.12189092776333513,\n",
       "  0.12184541914668291,\n",
       "  0.12179822244363994,\n",
       "  0.121755157041392,\n",
       "  0.12172060763179554,\n",
       "  0.12167404735706769,\n",
       "  0.12162212777301877,\n",
       "  0.12156940529098431,\n",
       "  0.12152428632816731,\n",
       "  0.12147360695301844,\n",
       "  0.12142733698006641,\n",
       "  0.12137747393777333,\n",
       "  0.12132936488976084,\n",
       "  0.12129190700719754,\n",
       "  0.12123320476383403,\n",
       "  0.12117661288638526,\n",
       "  0.12112372682688897,\n",
       "  0.12107324482404752,\n",
       "  0.1210229725431067,\n",
       "  0.12097237679470679,\n",
       "  0.12092206072158374,\n",
       "  0.12087125322950047,\n",
       "  0.12081343760564087,\n",
       "  0.12076928855049225,\n",
       "  0.12071578603208521,\n",
       "  0.12064065509996914,\n",
       "  0.12058619642055209,\n",
       "  0.12052307795382589,\n",
       "  0.12047091073101855,\n",
       "  0.12040922850260108,\n",
       "  0.12035296644436605,\n",
       "  0.120289356048532,\n",
       "  0.12022740452308026,\n",
       "  0.12016926131528945,\n",
       "  0.12010563328239719,\n",
       "  0.12004368122486397,\n",
       "  0.11998104045040134,\n",
       "  0.11991777111857821,\n",
       "  0.11985246531449503,\n",
       "  0.11979245010559211,\n",
       "  0.11972465331522822,\n",
       "  0.11965447371370362,\n",
       "  0.11958601311068877,\n",
       "  0.11952502796985681,\n",
       "  0.11945411288804857,\n",
       "  0.11938118019234029,\n",
       "  0.11931443422961767,\n",
       "  0.11924827435644617,\n",
       "  0.11918025280580964,\n",
       "  0.11911186078665308,\n",
       "  0.11904690339108676,\n",
       "  0.1189791430870876,\n",
       "  0.11890686360596607,\n",
       "  0.11885086638866368,\n",
       "  0.11877150087092249,\n",
       "  0.11870092321911729,\n",
       "  0.11861598655599077,\n",
       "  0.1185280546192875,\n",
       "  0.11845219105895863,\n",
       "  0.11837095473066778,\n",
       "  0.11828964623642613,\n",
       "  0.11821394645088579,\n",
       "  0.11814963123107929,\n",
       "  0.11806167979054835,\n",
       "  0.11798436060631028,\n",
       "  0.11789402493314573,\n",
       "  0.11781322683326105,\n",
       "  0.117736723928046,\n",
       "  0.11764734244362321,\n",
       "  0.11755732409866118,\n",
       "  0.11746461831245503,\n",
       "  0.11738401431725645,\n",
       "  0.11729901947913854,\n",
       "  0.11721900535675248,\n",
       "  0.11712774661020232,\n",
       "  0.11704141210022018,\n",
       "  0.11695119268684653,\n",
       "  0.11686723198820542,\n",
       "  0.11677888649452012,\n",
       "  0.11670034851652743,\n",
       "  0.11661419148956512,\n",
       "  0.11651502867778518,\n",
       "  0.11641627021858578,\n",
       "  0.11632039178167515,\n",
       "  0.11622533089157552,\n",
       "  0.1161329315351195,\n",
       "  0.11603593640280198,\n",
       "  0.11593805877620109,\n",
       "  0.11584144199888535,\n",
       "  0.11574741549010711,\n",
       "  0.11565007097497025,\n",
       "  0.11554982489536064,\n",
       "  0.11545207403525228,\n",
       "  0.11535899722180408,\n",
       "  0.11526319866983319,\n",
       "  0.11516685878390075,\n",
       "  0.11506220975805481,\n",
       "  0.11495894760334174,\n",
       "  0.11486027611630537,\n",
       "  0.1147559047445814,\n",
       "  0.11465512814168109,\n",
       "  0.11455132895524422,\n",
       "  0.11444532707652864,\n",
       "  0.11434468853318389,\n",
       "  0.11424073758502726,\n",
       "  0.11413335815342909,\n",
       "  0.11403490886597747,\n",
       "  0.1139337509879821,\n",
       "  0.11383229067300824,\n",
       "  0.11372859109002731,\n",
       "  0.11362102225425853,\n",
       "  0.11350572356808764,\n",
       "  0.11340182010226435,\n",
       "  0.11329822490637916,\n",
       "  0.11318417377833825,\n",
       "  0.11308887043492839,\n",
       "  0.11298273678157492,\n",
       "  0.11287288582309665,\n",
       "  0.11278121915266384,\n",
       "  0.11265838452240626,\n",
       "  0.11254062661057472,\n",
       "  0.11242505257601609,\n",
       "  0.11231785287068463,\n",
       "  0.11221043116491988,\n",
       "  0.11209376015436856,\n",
       "  0.11198009473972506,\n",
       "  0.11186724728625212,\n",
       "  0.11175560538738964,\n",
       "  0.11163799814982503,\n",
       "  0.11153132503957133,\n",
       "  0.11142208789342598,\n",
       "  0.11130471705376878,\n",
       "  0.11119385927582494,\n",
       "  0.11107657875424072,\n",
       "  0.11095848119776484,\n",
       "  0.11085156983024558,\n",
       "  0.11073482378670736,\n",
       "  0.1106262317371213,\n",
       "  0.11051631906508043,\n",
       "  0.1104001579406637,\n",
       "  0.11028264933593739,\n",
       "  0.11017080726752783,\n",
       "  0.11005914162809997,\n",
       "  0.10994730045793165,\n",
       "  0.10983671079249922,\n",
       "  0.109725011642039,\n",
       "  0.10960700231462789,\n",
       "  0.10948892914769288,\n",
       "  0.1093774629534178,\n",
       "  0.10925969787773067,\n",
       "  0.10914523562181613,\n",
       "  0.10903399146818278,\n",
       "  0.10891871724706402,\n",
       "  0.10880786891810779,\n",
       "  0.10869220110394798,\n",
       "  0.10857964113486304,\n",
       "  0.10846089176901605,\n",
       "  0.1083436060022424,\n",
       "  0.10823218351690719,\n",
       "  0.10811144586982543,\n",
       "  0.10799877046965289,\n",
       "  0.10788855257951975,\n",
       "  0.10778096242728955,\n",
       "  0.10766450569469074,\n",
       "  0.10755895157294783,\n",
       "  0.10744154829566588,\n",
       "  0.10733268576712907,\n",
       "  0.10721473796741714,\n",
       "  0.1071018193607433,\n",
       "  0.10699881156319721,\n",
       "  0.10688257111155129,\n",
       "  0.10677398226854519,\n",
       "  0.10667597708455699,\n",
       "  0.10656995571096482,\n",
       "  0.10645100571044645,\n",
       "  0.10633658612941861,\n",
       "  0.10622930297760422,\n",
       "  0.10611569377478139,\n",
       "  0.10601773365875183,\n",
       "  0.10590531710014296,\n",
       "  0.10579372991613403,\n",
       "  0.10568882553618683,\n",
       "  0.10557585468521152,\n",
       "  0.10548109994519686,\n",
       "  0.10536626450444259,\n",
       "  0.10525453909068272,\n",
       "  0.10514426718221037,\n",
       "  0.10503562225115427,\n",
       "  0.10493401411795125,\n",
       "  0.10482416609054249,\n",
       "  0.10471973174713811,\n",
       "  0.10461240400459461,\n",
       "  0.10450829226960147,\n",
       "  0.10440218364182763,\n",
       "  0.10430119726639238,\n",
       "  0.10419905051763985,\n",
       "  0.1040910949866819,\n",
       "  0.10399018153555624,\n",
       "  0.10389055852895504,\n",
       "  0.1037936336013226,\n",
       "  0.10369190986710564,\n",
       "  0.10359156010037893,\n",
       "  0.1034956779254501,\n",
       "  0.10339810159183331,\n",
       "  0.10329662260683829,\n",
       "  0.1031985090859682,\n",
       "  0.10309928947925255,\n",
       "  0.10300024366160329,\n",
       "  0.10290684247816087,\n",
       "  0.1028074635630617,\n",
       "  0.10270888417422819,\n",
       "  0.10261462563294599,\n",
       "  0.10252119752165642,\n",
       "  0.10242268860113671,\n",
       "  0.1023303647977207,\n",
       "  0.10223761172035975,\n",
       "  0.10214348090933213,\n",
       "  0.10205139862786046,\n",
       "  0.10196178984180421,\n",
       "  0.10188309847465582,\n",
       "  0.1018069777439102,\n",
       "  0.10170497081318454,\n",
       "  0.10161849492729183,\n",
       "  0.10154362902400436,\n",
       "  0.10142797302046896,\n",
       "  0.1013308891287885,\n",
       "  0.10124564308220743,\n",
       "  0.10116129644842445,\n",
       "  0.1010758648624947,\n",
       "  0.10097368598687104,\n",
       "  0.10088994948205593,\n",
       "  0.10079891437725548,\n",
       "  0.10071665739065203,\n",
       "  0.10062672667185743,\n",
       "  0.1005382524839001,\n",
       "  0.10045740875437152,\n",
       "  0.10037080981137271,\n",
       "  0.1002894727368665,\n",
       "  0.10020257657069713,\n",
       "  0.10011749899719921,\n",
       "  0.10003738190984074,\n",
       "  0.099955139606472843,\n",
       "  0.099874430790855104,\n",
       "  0.09979607697587338,\n",
       "  0.099713943687848319,\n",
       "  0.099633780621820461,\n",
       "  0.099562936081078815,\n",
       "  0.099487598685656001,\n",
       "  0.099410507962369582,\n",
       "  0.099336441016063981,\n",
       "  0.099263343521740849,\n",
       "  0.099190306181934945,\n",
       "  0.099105556049776999,\n",
       "  0.099029782850197215,\n",
       "  0.098938938547150815,\n",
       "  0.098862519462086185,\n",
       "  0.09879121159587731,\n",
       "  0.098710679133429846,\n",
       "  0.098639774287328605,\n",
       "  0.09856455661069892,\n",
       "  0.098487932426708405,\n",
       "  0.098415858552046154,\n",
       "  0.0983437836088705,\n",
       "  0.098277963614822439,\n",
       "  0.098216105769007092,\n",
       "  0.098139143915447008,\n",
       "  0.098065299890365429,\n",
       "  0.097994558928447051,\n",
       "  0.097927784863086176,\n",
       "  0.097857696310344702,\n",
       "  0.097792192593347205,\n",
       "  0.097727006423212054,\n",
       "  0.097658293407638527,\n",
       "  0.097600890260053086,\n",
       "  0.097527847693798644,\n",
       "  0.097471428024610118,\n",
       "  0.097416722258542865,\n",
       "  0.097362550391928621,\n",
       "  0.09729108573776396,\n",
       "  0.097219605085858835,\n",
       "  0.097145833600268156,\n",
       "  0.097081909446712175,\n",
       "  0.097019283353911759,\n",
       "  0.096950183458074463,\n",
       "  0.096883942207219298,\n",
       "  0.096820473947806726,\n",
       "  0.096756249338214806,\n",
       "  0.096696309801469274,\n",
       "  0.096636658101968045,\n",
       "  0.096572231323477281,\n",
       "  0.096505484394154059,\n",
       "  0.096444309437892201,\n",
       "  0.09638364928728696,\n",
       "  0.096323980347900573,\n",
       "  0.096262996703681561,\n",
       "  0.096201786590852156,\n",
       "  0.096143630744064651,\n",
       "  0.096085721848919711,\n",
       "  0.09602912334675226,\n",
       "  0.095970498349676692,\n",
       "  0.095913176796137228,\n",
       "  0.095856583035076881,\n",
       "  0.095800632233352903,\n",
       "  0.095742803061427462,\n",
       "  0.09568585392443027,\n",
       "  0.095627606118152964,\n",
       "  0.09557008839011652,\n",
       "  0.09551241464871188,\n",
       "  0.095455053779589932,\n",
       "  0.095401204785810628,\n",
       "  0.095345090915109038,\n",
       "  0.095290370065228142,\n",
       "  0.095234987570538276,\n",
       "  0.095181051583288476,\n",
       "  0.095127429713363076,\n",
       "  0.095071770670060923,\n",
       "  0.095018873182649899,\n",
       "  0.094968480413399739,\n",
       "  0.094917943984674708,\n",
       "  0.094868525538782153,\n",
       "  0.094811401213192703,\n",
       "  0.094756709799012573,\n",
       "  0.094704768790681432,\n",
       "  0.094648914699155581,\n",
       "  0.094596332474487149,\n",
       "  0.09454515975969402,\n",
       "  0.094494139740212757,\n",
       "  0.094442478606113087,\n",
       "  0.094390989093509695,\n",
       "  0.094337121808793375,\n",
       "  0.094289864133685175,\n",
       "  0.09424307486709696,\n",
       "  0.094182437894208493,\n",
       "  0.094130576256360121,\n",
       "  0.094082625637651823,\n",
       "  0.094039894020486819,\n",
       "  0.093993007208308957,\n",
       "  0.093934617329500161,\n",
       "  0.093887748296955065,\n",
       "  0.0938346786739543,\n",
       "  0.093776064411377216,\n",
       "  0.093725407792401225,\n",
       "  0.093673297503724592,\n",
       "  0.093623881554523294,\n",
       "  0.093575998594527102,\n",
       "  0.093526944197907178,\n",
       "  0.093477065626646441,\n",
       "  0.093429667440192044,\n",
       "  0.093379816919050493,\n",
       "  0.093330150421319341,\n",
       "  0.0932809172214632,\n",
       "  0.093232291797525749,\n",
       "  0.093184052610917376,\n",
       "  0.093132697324111724,\n",
       "  0.093082352377759553,\n",
       "  0.093035288402513461,\n",
       "  0.092991974136608715,\n",
       "  0.092940680086674277,\n",
       "  0.092890649816889242,\n",
       "  0.092837339317827713,\n",
       "  0.092788955492538863,\n",
       "  0.092740640620183501,\n",
       "  0.092692337227668897,\n",
       "  0.092641045472873412,\n",
       "  0.092593843965497274,\n",
       "  0.092543172605311044,\n",
       "  0.092494614922320403,\n",
       "  0.092443469723755611,\n",
       "  0.092393813244494943,\n",
       "  0.092341729225418029,\n",
       "  0.092292759015967923,\n",
       "  0.092240503862733136,\n",
       "  0.092189740149861379,\n",
       "  0.092140804072372989,\n",
       "  0.092090630153051078,\n",
       "  0.09204324592254183,\n",
       "  0.091993506132668559,\n",
       "  0.091941345387293205,\n",
       "  0.091893768874449111,\n",
       "  0.091841197332762234,\n",
       "  0.091789152217955208,\n",
       "  0.091736750341308099,\n",
       "  0.091686479145157512,\n",
       "  0.091633052021703784,\n",
       "  0.091579592936394935,\n",
       "  0.091528498663859106,\n",
       "  0.091476563772768887,\n",
       "  0.091426794870557798,\n",
       "  0.091371253256196272,\n",
       "  0.091318789984214582,\n",
       "  0.091268614698072278,\n",
       "  0.09121505825446688,\n",
       "  0.091160130457610525,\n",
       "  0.091108163403201686,\n",
       "  0.0910469380845811,\n",
       "  0.09098837130351467,\n",
       "  0.090932153143818445,\n",
       "  0.090876239635071382,\n",
       "  0.090825416286903965,\n",
       "  0.090758427626795826,\n",
       "  0.090700958450308317,\n",
       "  0.090643286943136767,\n",
       "  0.090579128808315798,\n",
       "  0.09051752865813531,\n",
       "  0.09045490026103363,\n",
       "  0.090392679982681925,\n",
       "  0.090329015531345494,\n",
       "  0.090266302264538287,\n",
       "  0.090202493391100563,\n",
       "  0.090138607135412496,\n",
       "  0.090073182880333141,\n",
       "  0.090009244639148292,\n",
       "  0.089941676769465267,\n",
       "  0.089875693696254644,\n",
       "  0.089810093707036284,\n",
       "  0.089746919910432765,\n",
       "  0.089675292331107367,\n",
       "  0.089611520100643965,\n",
       "  0.089544658036396663,\n",
       "  0.089471406309739654,\n",
       "  0.089394489034469116,\n",
       "  0.089320275967882487,\n",
       "  0.089239094481461737,\n",
       "  0.089163376553556092,\n",
       "  0.089090259621835741,\n",
       "  0.08900931648914967,\n",
       "  0.088924794444579722,\n",
       "  0.088843944266766145,\n",
       "  0.088759843845432368,\n",
       "  0.08868012669042924,\n",
       "  0.088591674761904271,\n",
       "  0.088501455751288483,\n",
       "  0.088411414120807538,\n",
       "  0.088324011298845984,\n",
       "  0.088236970357030861,\n",
       "  0.08815150467737716,\n",
       "  0.088057642260881919,\n",
       "  0.087966931465441253,\n",
       "  0.087862723424253816,\n",
       "  0.087762555568210471,\n",
       "  0.087655975081747259,\n",
       "  0.087552010602967009,\n",
       "  0.087447258123147048,\n",
       "  0.087338453091032497,\n",
       "  0.087230167048902324,\n",
       "  0.087120979868573367,\n",
       "  0.087007727186536946,\n",
       "  0.086893482387277649,\n",
       "  0.086777289806408586,\n",
       "  0.086658898482442154,\n",
       "  0.086538711586226447,\n",
       "  0.08641737429975252,\n",
       "  0.086296166796346732,\n",
       "  0.086165113971363158,\n",
       "  0.086035202837776131,\n",
       "  0.085903469300230406,\n",
       "  0.085767396486345404,\n",
       "  0.085629684309505377,\n",
       "  0.085489845420052016,\n",
       "  0.085346485178751264,\n",
       "  0.085202712736614686,\n",
       "  0.085053377560900784,\n",
       "  0.084903669982474145,\n",
       "  0.084753595792616432,\n",
       "  0.084595962561369184,\n",
       "  0.084437337463367595,\n",
       "  0.084272360711522665,\n",
       "  0.084109052608453708,\n",
       "  0.083945904834694815,\n",
       "  0.083772397019178019,\n",
       "  0.083603092994716327,\n",
       "  0.083423952403774412,\n",
       "  0.08323234614438331,\n",
       "  0.083051684443841062,\n",
       "  0.082856825899806141,\n",
       "  0.082658409712141695,\n",
       "  0.082462426142175096,\n",
       "  0.082267392190758556,\n",
       "  0.082063176565209603,\n",
       "  0.08185949086082954,\n",
       "  0.081652096958998055,\n",
       "  0.081429096823792735,\n",
       "  0.081208849151548454,\n",
       "  0.080993997982152066,\n",
       "  0.080773362505743809,\n",
       "  0.080549381082343607,\n",
       "  0.080310952095730775,\n",
       "  0.080069399486446563,\n",
       "  0.079816519625795113,\n",
       "  0.079576131298607855,\n",
       "  0.079316189707878348,\n",
       "  0.079060764631403518,\n",
       "  0.078800499338896129,\n",
       "  0.078543393380603316,\n",
       "  0.078275318920495759,\n",
       "  0.078001651252672527,\n",
       "  0.077725664631873803,\n",
       "  0.077440037398001121,\n",
       "  0.077160947275037223,\n",
       "  0.076879342292917499,\n",
       "  0.076591176975814065,\n",
       "  0.076289587510553147,\n",
       "  0.075978460711246698,\n",
       "  0.075667580818847308,\n",
       "  0.075358217404948552,\n",
       "  0.075040044985848015,\n",
       "  0.074727595616550305,\n",
       "  0.074402560858222444,\n",
       "  0.074071881544314516,\n",
       "  0.073741609186753557,\n",
       "  0.073406844001793356,\n",
       "  0.073066062645870677,\n",
       "  0.072723023416413207,\n",
       "  0.072373602702720044,\n",
       "  0.072020924110704473,\n",
       "  0.071666465245187716,\n",
       "  0.071303500592715965,\n",
       "  0.070941116553179334,\n",
       "  0.070576872413125602,\n",
       "  0.07020252710643192,\n",
       "  0.069823242052076434,\n",
       "  0.069441374335218853,\n",
       "  0.069056278479423652,\n",
       "  0.068672518961883644,\n",
       "  0.068279143995952293,\n",
       "  0.067889125859229099,\n",
       "  0.067487457701849565,\n",
       "  0.067093327731820279,\n",
       "  0.066693190902703564,\n",
       "  0.066278312044107862,\n",
       "  0.065863519755933519,\n",
       "  0.06545677456601387,\n",
       "  0.065032096838193401,\n",
       "  0.064619519869250269,\n",
       "  0.064199440417309864,\n",
       "  0.063753200008312833,\n",
       "  0.063331565091571743,\n",
       "  0.062907103990865187,\n",
       "  0.062463477873335262,\n",
       "  0.062017621923638667,\n",
       "  0.061565428504020601,\n",
       "  0.061122828023230914,\n",
       "  0.06067837890939861,\n",
       "  0.060232548202501165,\n",
       "  0.059783577908865355,\n",
       "  0.05933199583986741,\n",
       "  0.058878901986801215,\n",
       "  0.058425416438645628,\n",
       "  0.057976632085632647,\n",
       "  0.057515790341400364,\n",
       "  0.057063168832687354,\n",
       "  0.056603647311194022,\n",
       "  0.056145159046263431,\n",
       "  0.055692143187873071,\n",
       "  0.055237367073098058,\n",
       "  0.054774530206953595,\n",
       "  0.054312004254401122,\n",
       "  0.053858581857934636,\n",
       "  0.053401627222651502,\n",
       "  0.052937908535386616,\n",
       "  0.052475994367353083,\n",
       "  0.052020099155699565,\n",
       "  0.051556214203556244,\n",
       "  0.051099534455174789,\n",
       "  0.050646139271622821,\n",
       "  0.050197403025739516,\n",
       "  0.0497465590434698,\n",
       "  0.049301480446270488,\n",
       "  0.048842934214498743,\n",
       "  0.048400954889940936,\n",
       "  0.047938487306879662,\n",
       "  0.047492112874174285,\n",
       "  0.047045912616667823,\n",
       "  0.046609065940873412,\n",
       "  0.046178700236575103,\n",
       "  0.045746194676768881,\n",
       "  0.045295444330168286,\n",
       "  0.044855109320064715,\n",
       "  0.044424359468807809,\n",
       "  0.043999887149582695,\n",
       "  0.04357334676606938,\n",
       "  0.043151541291805748,\n",
       "  0.042739007779205349,\n",
       "  0.04232550798885678,\n",
       "  0.041906915996776636,\n",
       "  0.041501635492715822,\n",
       "  0.041084898219387565,\n",
       "  0.040679739331010309,\n",
       "  0.040277391731374547,\n",
       "  0.039881375874078348,\n",
       "  0.039486659882424731,\n",
       "  0.039095515618398996,\n",
       "  0.038711890894853142,\n",
       "  0.038323903969869073,\n",
       "  0.037945412565687849,\n",
       "  0.037567441556668767,\n",
       "  0.037198610353532495,\n",
       "  0.036832661950828335,\n",
       "  0.036473751654932246,\n",
       "  0.036106914691487496,\n",
       "  0.035754127864101759,\n",
       "  0.035405698157219917,\n",
       "  0.035040092229042745,\n",
       "  0.034690784803669918,\n",
       "  0.034346488764310949,\n",
       "  0.034003457075438559,\n",
       "  0.033662455428728623,\n",
       "  0.033331561696036724,\n",
       "  0.033004241056643353,\n",
       "  0.032683245510193713,\n",
       "  0.03235393685557629,\n",
       "  0.032033552310044677,\n",
       "  0.031719634448482567,\n",
       "  0.031409918456068817,\n",
       "  0.031100356308158422,\n",
       "  0.030796753291615131,\n",
       "  0.030497792906730457,\n",
       "  0.030201120267286809,\n",
       "  0.029909911731801284,\n",
       "  0.029624480745176839,\n",
       "  0.029338073548442312,\n",
       "  0.029060910794985701,\n",
       "  0.028775102977974511,\n",
       "  0.028499353931843999,\n",
       "  0.028230316996917977,\n",
       "  0.027964047956540145,\n",
       "  0.0276940487812865,\n",
       "  0.027430895881143551,\n",
       "  0.027172073993784095,\n",
       "  0.026914734851720731,\n",
       "  0.026664230711719722,\n",
       "  0.026413577408645271,\n",
       "  0.026170522900343551,\n",
       "  0.025926833511556769,\n",
       "  0.025685440445807225,\n",
       "  0.025447981515638433,\n",
       "  0.025217088724462357,\n",
       "  0.024984484220391519,\n",
       "  0.024758930728900889,\n",
       "  0.024529995838237825,\n",
       "  0.024307094489165244,\n",
       "  0.024087726193031893,\n",
       "  0.023873669504185374,\n",
       "  0.023663020111177952,\n",
       "  0.023454641673784672,\n",
       "  0.023244338316709117,\n",
       "  0.023039588166013952,\n",
       "  0.022838958273852697,\n",
       "  0.022632701723804046,\n",
       "  0.022437142916532982,\n",
       "  0.022242614038693438,\n",
       "  0.022046869325204221,\n",
       "  0.021855432073390323,\n",
       "  0.02166917932955684,\n",
       "  0.021481253605572136,\n",
       "  0.021298979419829028,\n",
       "  0.021116299517731984,\n",
       "  0.020937451207418439,\n",
       "  0.020760875518104585,\n",
       "  0.020586956254686546,\n",
       "  0.020414939783778393,\n",
       "  0.020245118658429942,\n",
       "  0.020077454710481956,\n",
       "  0.019912273661203302,\n",
       "  0.019749086854734831,\n",
       "  0.019588063744504516,\n",
       "  0.019429142023950345,\n",
       "  0.019272136111760221,\n",
       "  0.01911723346104036,\n",
       "  0.018963712267289323,\n",
       "  0.018812236426729918,\n",
       "  0.018663489157049976,\n",
       "  0.018515615399447828,\n",
       "  0.018369591737447236,\n",
       "  0.018225936947744121,\n",
       "  0.018083037186915809,\n",
       "  0.017942486270107947,\n",
       "  0.01780354768830297,\n",
       "  0.01766647654832771,\n",
       "  0.017531764627086156,\n",
       "  0.017397856963229045,\n",
       "  0.017265571789496524,\n",
       "  0.017134717474037265,\n",
       "  0.017006123404034429,\n",
       "  0.016879176659593601,\n",
       "  0.016752958091030078,\n",
       "  0.016628636358031735,\n",
       "  0.01650593711607079,\n",
       "  0.016385071629017443,\n",
       "  0.01626491306069491,\n",
       "  0.016146447675783666,\n",
       "  0.016030111360125186,\n",
       "  0.015914125673458054,\n",
       "  0.015800420729073849,\n",
       "  0.015686590080016178,\n",
       "  0.015574355270162019,\n",
       "  0.015464541394541334,\n",
       "  0.01535614004497016,\n",
       "  0.015248901754853991,\n",
       "  0.015142032331593192,\n",
       "  0.015036135337663799,\n",
       "  0.014931475142847477,\n",
       "  0.014828506311198288,\n",
       "  0.01472672778077427,\n",
       "  0.014626092406193083,\n",
       "  0.014526611980758228,\n",
       "  0.01442870169098541,\n",
       "  0.01433198367075513,\n",
       "  0.014235431359861498,\n",
       "  0.014140571427645949,\n",
       "  0.014046252679176344,\n",
       "  0.013952967071262088,\n",
       "  0.01386059812856813,\n",
       "  0.013769630921024022,\n",
       "  0.013679500128660274,\n",
       "  0.013590431235259302,\n",
       "  0.013502707864152121,\n",
       "  0.013415893533689379,\n",
       "  0.013329479224917191,\n",
       "  0.013244301987895887,\n",
       "  0.013160266173763251,\n",
       "  0.013077098473939675,\n",
       "  0.01299482827173243,\n",
       "  0.012912686754466746,\n",
       "  0.012831966260098603,\n",
       "  0.012751936217090813,\n",
       "  0.012672791507153067,\n",
       "  0.012594391115717186,\n",
       "  0.012517141744769564,\n",
       "  0.012440597782756753,\n",
       "  0.012365090434765687,\n",
       "  0.012290317881709333,\n",
       "  0.012215706129804191,\n",
       "  0.012142469916774834,\n",
       "  0.012069726291264134,\n",
       "  0.011997557780378323,\n",
       "  0.011926462282452321,\n",
       "  0.01185587017451744,\n",
       "  0.011786002838567025,\n",
       "  0.011716857759519887,\n",
       "  0.011648288317067492,\n",
       "  0.011580601451637354,\n",
       "  0.01151357057214587,\n",
       "  0.011447223695547858,\n",
       "  0.011381528223876608,\n",
       "  0.01131643519106041,\n",
       "  0.011252030494236355,\n",
       "  0.011188268650986684,\n",
       "  0.011125131432171569,\n",
       "  0.011062716326351937,\n",
       "  0.011001018132188727,\n",
       "  0.010939839391194646,\n",
       "  0.010879128083243823,\n",
       "  0.010818716423790583,\n",
       "  0.010759058450879877,\n",
       "  0.010700061620461068,\n",
       "  0.010641820997687408,\n",
       "  0.010583844524322388,\n",
       "  0.01052652803978628,\n",
       "  0.010469855017167393,\n",
       "  0.01041355980903203,\n",
       "  0.010357769946461284,\n",
       "  0.010302742135005767,\n",
       "  0.010248116906692762,\n",
       "  0.01019382121781497,\n",
       "  0.010140268776467898,\n",
       "  0.010087006249169715,\n",
       "  0.010034094726787651,\n",
       "  0.0099815929831150868,\n",
       "  0.0099300022855078329,\n",
       "  0.0098786933141541498,\n",
       "  0.0098280289898052577,\n",
       "  0.0097776294821826683,\n",
       "  0.0097277789935109622,\n",
       "  0.0096782474965331784,\n",
       "  0.0096289680764445225,\n",
       "  0.0095802398503547354,\n",
       "  0.0095320314621154048,\n",
       "  0.0094842390650416442,\n",
       "  0.0094368956546489937,\n",
       "  0.0093900477705063518,\n",
       "  0.0093436263247702964,\n",
       "  0.0092975565643234771,\n",
       "  0.009251768245710135,\n",
       "  0.0092064427968294709,\n",
       "  0.0091615252887759183,\n",
       "  0.0091170693633106197,\n",
       "  0.009073046755533885,\n",
       "  0.0090293621763960184,\n",
       "  0.0089859169976997423,\n",
       "  0.0089428608220948804,\n",
       "  0.0089002070620308529,\n",
       "  0.0088578650510830696,\n",
       "  0.0088159647976012272,\n",
       "  0.008774338168153999,\n",
       "  0.0087331349054325311,\n",
       "  0.0086922493559858146,\n",
       "  0.0086517044369309529,\n",
       "  0.0086114907356388253,\n",
       "  0.0085715200752844375,\n",
       "  0.0085319313347459111,\n",
       "  0.00849268094904327,\n",
       "  0.0084537705393066057,\n",
       "  0.0084151571558231369,\n",
       "  0.0083769031267188643,\n",
       "  0.0083388740371284336,\n",
       "  0.0083012387038790061,\n",
       "  0.0082638558158897937,\n",
       "  0.0082267832306286773,\n",
       "  0.0081900010208825237,\n",
       "  0.0081535103228503516,\n",
       "  0.0081173474208185801,\n",
       "  0.0080814829157138633,\n",
       "  0.0080458050092232208,\n",
       "  0.0080104631428447558,\n",
       "  0.0079754076486121556,\n",
       "  0.0079405995065607027,\n",
       "  0.0079061369680302925,\n",
       "  0.007871867629442704,\n",
       "  0.0078378878725573996,\n",
       "  0.0078041721566273741,\n",
       "  0.0077707100099767244,\n",
       "  0.0077375643669369215,\n",
       "  0.0077046548745034037,\n",
       "  0.007671872510579528,\n",
       "  0.0076394251790292359,\n",
       "  0.0076071771152541341,\n",
       "  0.0075752710862741664,\n",
       "  0.0075435069731866946,\n",
       "  0.0075120004445503978,\n",
       "  0.0074807339363967456,\n",
       "  0.0074496988510142957,\n",
       "  0.0074188998665216006,\n",
       "  0.0073883289249703438,\n",
       "  0.007358036612044417,\n",
       "  0.0073279323077379832,\n",
       "  0.0072980507760488497,\n",
       "  0.0072684084028026182,\n",
       "  0.0072389137688976448,\n",
       "  0.0072096822151215857,\n",
       "  0.0071806436528197761,\n",
       "  0.0071518257201511476,\n",
       "  0.00712320704821842,\n",
       "  0.0070947981637635993,\n",
       "  0.0070666109625607786,\n",
       "  0.007038614005935924,\n",
       "  0.0070108211944143609,\n",
       "  0.0069832332184956176,\n",
       "  0.006955828610877836,\n",
       "  0.0069286243672355653,\n",
       "  0.0069016000848627166,\n",
       "  0.0068747763209040715,\n",
       "  0.0068481411151550108,\n",
       "  0.0068216840193490421,\n",
       "  0.006795412063857878,\n",
       "  0.006769352448047973,\n",
       "  0.0067434554083744486,\n",
       "  0.0067177411806869838,\n",
       "  0.006692225129138675,\n",
       "  0.00666683269527691,\n",
       "  0.0066416096270361744,\n",
       "  0.0066165918781655852,\n",
       "  0.0065917381833893035,\n",
       "  0.0065670388419167766,\n",
       "  0.0065425112499181426,\n",
       "  0.0065181598273987874,\n",
       "  0.0064939579425835397,\n",
       "  0.0064699382135874946,\n",
       "  0.0064460659518849181,\n",
       "  0.0064223707293143079,\n",
       "  0.0063988248016099477,\n",
       "  0.0063754280335316634,\n",
       "  0.0063521915727399857,\n",
       "  0.006329097173317649,\n",
       "  0.0063061541139676734,\n",
       "  0.0062833654735002919,\n",
       "  0.0062607294684527181,\n",
       "  0.0062382432682353117,\n",
       "  ...],\n",
       " 20000)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's have our dataset D\n",
    "X = np.array([[1,1],[1,0],[0,1],[0,0]])\n",
    "# Let's have our targets, following the truth table presented above\n",
    "y = np.array([[0],[1],[1],[0]])\n",
    "\n",
    "# Now, let's create and train the neural network!\n",
    "xorNetwork = MultilayerNeuralNetwork(arch=[2,2,1], alpha=0.5)\n",
    "xorNetwork.fit(X, y, batch_size=1, epochs = 20000, displayUpdate=100, max_loss=0.0000001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com nosso modelo trainado, podemos checar se ele, de fato, resolveu o problema do XOR, ou seja, se ele consegue classificar (separar) corretamente os pontos segundo a tabela verdade:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.,  1.,  0.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(xorNetwork.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST\n",
    "\n",
    "O MNIST é um *dataset* massivamente utilizado pelos estudiosos de Machine Learning composto\n",
    "por imagens de dígitos de 0 a 9. Ele possui 60000 exemplos de treino e 10000 de testes. \n",
    "Os vetores de características são 784-dimensionais ($28 \\times 28$ pixels por imagem),\n",
    "com componentes assumindo valores em $[0,255]$. O propósito é corretamente classificar\n",
    "os dígitos desse *dataset*!\n",
    "\n",
    "A biblioteca `sklearn` oferece o uma amostra do MNIST por meio de comandos simples. \n",
    "Vamos utilizá-los para obter esse *dataset* e, com ele,\n",
    "treinar uma rede neural especializada em classificar\n",
    "seus dígitos de 0 a 9!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading MNIST dataset\n",
      "[INFO] samples: 1797, dim: 64\n",
      "[INFO] training network...\n",
      "Epoch: 1, Loss: 1.3069588\n",
      "Epoch: 11, Loss: 0.1292624\n",
      "Epoch: 21, Loss: 0.0478585\n",
      "Epoch: 31, Loss: 0.0260433\n",
      "Epoch: 41, Loss: 0.0176774\n",
      "Epoch: 51, Loss: 0.0134176\n",
      "Epoch: 61, Loss: 0.0109272\n",
      "Epoch: 71, Loss: 0.0087321\n",
      "Epoch: 81, Loss: 0.0064190\n",
      "Epoch: 91, Loss: 0.0053530\n",
      "Stopped by epochs criterion.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([1.3069587704901993,\n",
       "  0.44760145312258043,\n",
       "  0.44083812298800484,\n",
       "  0.42600661048772409,\n",
       "  0.39199679811103977,\n",
       "  0.33121760255439064,\n",
       "  0.25990256086056496,\n",
       "  0.20371079524360708,\n",
       "  0.17205493288025642,\n",
       "  0.14646734622462959,\n",
       "  0.12926242090851844,\n",
       "  0.11609347537921019,\n",
       "  0.10597565006926474,\n",
       "  0.098120119217557741,\n",
       "  0.091944445492395943,\n",
       "  0.084775405936902123,\n",
       "  0.077865001086400279,\n",
       "  0.067307318198011779,\n",
       "  0.059779606184095502,\n",
       "  0.051999442044419204,\n",
       "  0.047858477377481293,\n",
       "  0.044717040351381826,\n",
       "  0.042295840027029276,\n",
       "  0.038781933290986337,\n",
       "  0.035821933007658451,\n",
       "  0.032368974066504991,\n",
       "  0.03087931596265045,\n",
       "  0.030299368349492838,\n",
       "  0.028214300185356284,\n",
       "  0.02624749366052458,\n",
       "  0.026043312602176041,\n",
       "  0.025845461542043695,\n",
       "  0.023927751754497618,\n",
       "  0.022506500564112006,\n",
       "  0.022058478675433951,\n",
       "  0.022980564207896587,\n",
       "  0.019829557487995638,\n",
       "  0.019965366087611978,\n",
       "  0.020063418156673465,\n",
       "  0.01929828911442949,\n",
       "  0.01767741071527941,\n",
       "  0.017035101020897996,\n",
       "  0.018549542843858412,\n",
       "  0.016718916843154727,\n",
       "  0.015538758651081459,\n",
       "  0.01547492887165814,\n",
       "  0.015413883714954835,\n",
       "  0.015095578842950545,\n",
       "  0.013803481852166226,\n",
       "  0.013743488322052532,\n",
       "  0.013417571037225868,\n",
       "  0.012566997139821312,\n",
       "  0.01286049729982312,\n",
       "  0.011944379222000593,\n",
       "  0.011982751150742632,\n",
       "  0.011504585860063483,\n",
       "  0.01118515556044492,\n",
       "  0.011067050450472564,\n",
       "  0.010838924424093793,\n",
       "  0.01164880864971439,\n",
       "  0.010927217360385573,\n",
       "  0.010025621763297911,\n",
       "  0.010218105059393202,\n",
       "  0.0097441751077214558,\n",
       "  0.0099992862615684366,\n",
       "  0.0098411208186364035,\n",
       "  0.0090016946480128684,\n",
       "  0.0087017321760973574,\n",
       "  0.0088078219182687132,\n",
       "  0.0080802700072764837,\n",
       "  0.0087321378782380509,\n",
       "  0.0080748377520795771,\n",
       "  0.0078882610975682648,\n",
       "  0.0081548423307601214,\n",
       "  0.0086629096455036487,\n",
       "  0.0071251816470172874,\n",
       "  0.0073716046530972563,\n",
       "  0.0069058496520293606,\n",
       "  0.0066853865881748523,\n",
       "  0.0067750300954191947,\n",
       "  0.0064190244039945277,\n",
       "  0.0063151318064701666,\n",
       "  0.0062518473079907133,\n",
       "  0.0062652813499722015,\n",
       "  0.0060767899144410168,\n",
       "  0.0059627712935284259,\n",
       "  0.0058413512907724346,\n",
       "  0.0059622136818832565,\n",
       "  0.0054608662116975024,\n",
       "  0.0054110435249075644,\n",
       "  0.0053529925126071199,\n",
       "  0.0054408273734502296,\n",
       "  0.0054147693024819612,\n",
       "  0.0053158399792359191,\n",
       "  0.0050583181849105669,\n",
       "  0.0049702616458199124,\n",
       "  0.0050359032287913552,\n",
       "  0.004898239370124664,\n",
       "  0.0047995747426667372,\n",
       "  0.0049630048185446574,\n",
       "  0.0046304261229112862],\n",
       " 100)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import sklearn tools\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import datasets\n",
    "\n",
    "# Load a sample of MNIST through simple sklearn commands\n",
    "print(\"[INFO] loading MNIST dataset\")\n",
    "digits = datasets.load_digits()\n",
    "data = digits.data.astype(\"float\")\n",
    "data = (data - data.min()) / (data.max() - data.min())    # normalize data\n",
    "print(\"[INFO] samples: {}, dim: {}\".format(data.shape[0], data.shape[1]))\n",
    "\n",
    "# Split the dataset into train and test\n",
    "(trainX, testX, trainY, testY) = train_test_split(data, digits.target, test_size=0.25)\n",
    "\n",
    "# Binarize labels\n",
    "trainY = LabelBinarizer().fit_transform(trainY)\n",
    "testY = LabelBinarizer().fit_transform(testY)\n",
    "\n",
    "# Train the neural network\n",
    "print(\"[INFO] training network...\")\n",
    "mnistNN = MultilayerNeuralNetwork(arch=[trainX.shape[1], 32, 16, 10], alpha=0.1)\n",
    "mnistNN.fit(trainX, trainY, epochs=100, batch_size=1, max_loss=0.00001, displayUpdate=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma vez treinada a rede, podemos checar seu desempenho no conjunto de testes, por meio da função `classification_report`, que fornece índices de desempenho:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating network...\n",
      "(450, 64)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        44\n",
      "          1       0.98      0.98      0.98        42\n",
      "          2       0.98      1.00      0.99        46\n",
      "          3       0.94      0.98      0.96        47\n",
      "          4       1.00      0.98      0.99        45\n",
      "          5       0.93      0.93      0.93        44\n",
      "          6       1.00      0.98      0.99        46\n",
      "          7       0.98      0.98      0.98        49\n",
      "          8       0.88      0.94      0.91        47\n",
      "          9       1.00      0.90      0.95        40\n",
      "\n",
      "avg / total       0.97      0.97      0.97       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] evaluating network...\")\n",
    "# Test the model\n",
    "print(testX.shape)\n",
    "predictions = mnistNN.predict(testX)\n",
    "predictions = predictions.T.argmax(axis=1)\n",
    "print(classification_report(testY.argmax(axis=1), predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes Neurais com Keras\n",
    "\n",
    "O que fizemos até então geralmente não é feito na prática. Existem bibliotecas mais robustas e otimizadas para se trabalhar com redes neurais e outros modelos. Uma delas é a Keras, que permite o treino e avaliação de redes neurais com poucas linhas de código. Abaixo, segue um exemplo, também aplicado ao *dataset* MNIST:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import sklearn and keras tools\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import datasets\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from keras.optimizers import SGD\n",
    "import numpy as np\n",
    "\n",
    "# Download the full MNIST dataset\n",
    "dataset = datasets.fetch_mldata(\"MNIST Original\")\n",
    "\n",
    "# Normalize data\n",
    "data = dataset.data.astype(\"float\")/255.0\n",
    "\n",
    "# Split data into sets\n",
    "(trainX, testX, trainY, testY) = train_test_split(data, dataset.target, test_size=0.25)\n",
    "\n",
    "# Binarize labels\n",
    "lb = LabelBinarizer()\n",
    "trainY = lb.fit_transform(trainY)\n",
    "testY = lb.transform(testY)\n",
    "\n",
    "# Prepare the feedforward neural network with keras\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_shape=(784,), activation=\"sigmoid\"))\n",
    "model.add(Dense(128, activation=\"sigmoid\"))\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "# Train the neural network\n",
    "print(\"[INFO] training...\")\n",
    "sgd = SGD(0.1)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=sgd, metrics=[\"accuracy\"])\n",
    "H = model.fit(trainX, trainY, validation_data=(testX, testY), epochs=100, batch_size=128)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
